{
    "agent": "gpt-w-shell",
    "session_id": "7e621fda-2da2-47ec-943f-011633ef514f",
    "problem_id": "astronomy_shop_kafka_queue_problems-localization-1",
    "start_time": 1755634082.642747,
    "end_time": 1755634804.198231,
    "trace": [
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl get pods -n astronomy-shop -o wide\")\n```"
        },
        {
            "role": "env",
            "content": "NAME                               READY   STATUS     RESTARTS   AGE   IP             NODE          NOMINATED NODE   READINESS GATES\naccounting-567f87bbcd-cphcl        1/1     Running    0          42s   10.244.1.167   kind-worker   <none>           <none>\nad-856c77f595-rsnfm                1/1     Running    0          42s   10.244.1.170   kind-worker   <none>           <none>\ncart-6fd857c656-2mlnf              1/1     Running    0          42s   10.244.1.166   kind-worker   <none>           <none>\ncheckout-5bc54f8cd8-mkhs7          1/1     Running    0          40s   10.244.1.185   kind-worker   <none>           <none>\ncurrency-5864f94d89-qv8tf          1/1     Running    0          39s   10.244.1.188   kind-worker   <none>           <none>\nemail-59d9ffc758-fvrxd             1/1     Running    0          40s   10.244.1.169   kind-worker   <none>           <none>\nflagd-5854dbdc5d-flhts             0/2     Init:0/1   0          0s    <none>         kind-worker   <none>           <none>\nflagd-86575d5796-vb6np             2/2     Running    0          42s   10.244.1.172   kind-worker   <none>           <none>\nfraud-detection-65868bcdb5-8sdxc   1/1     Running    0          42s   10.244.1.174   kind-worker   <none>           <none>\nfrontend-7d6b77c58-2r54d           1/1     Running    0          41s   10.244.1.180   kind-worker   <none>           <none>\nfrontend-proxy-548b4649d7-99lhx    1/1     Running    0          40s   10.244.1.184   kind-worker   <none>           <none>\ngrafana-6b9fb84fb7-xwc7m           1/1     Running    0          42s   10.244.1.165   kind-worker   <none>           <none>\nimage-provider-7f5bc6bf-c78nd      1/1     Running    0          42s   10.244.1.183   kind-worker   <none>           <none>\njaeger-55f499595b-t7bpk            1/1     Running    0          39s   10.244.1.187   kind-worker   <none>           <none>\nkafka-595d889c56-5cwc9             1/1     Running    0          41s   10.244.1.177   kind-worker   <none>           <none>\nload-generator-68b6f899f5-f5d24    1/1     Running    0          41s   10.244.1.171   kind-worker   <none>           <none>\nopensearch-0                       1/1     Running    0          42s   10.244.1.178   kind-worker   <none>           <none>\notel-collector-758b8784c-4k2h5     1/1     Running    0          42s   10.244.1.179   kind-worker   <none>           <none>\npayment-7597577cb5-9nmtb           1/1     Running    0          42s   10.244.1.176   kind-worker   <none>           <none>\nproduct-catalog-6988cd5f49-v8xnv   1/1     Running    0          42s   10.244.1.168   kind-worker   <none>           <none>\nprometheus-58b7bfb774-s6bm9        1/1     Running    0          39s   10.244.1.173   kind-worker   <none>           <none>\nquote-78bf8788-sddc8               1/1     Running    0          41s   10.244.1.186   kind-worker   <none>           <none>\nrecommendation-7b49c8cb75-54hpj    1/1     Running    0          41s   10.244.1.182   kind-worker   <none>           <none>\nshipping-7f445d59dc-g9xhh          1/1     Running    0          40s   10.244.1.175   kind-worker   <none>           <none>\nvalkey-cart-6475dcc67f-pjrgx       1/1     Running    0          40s   10.244.1.181   kind-worker   <none>           <none>\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl describe pod flagd-5854dbdc5d-flhts -n astronomy-shop\")\n```"
        },
        {
            "role": "env",
            "content": "Name:             flagd-5854dbdc5d-flhts\nNamespace:        astronomy-shop\nPriority:         0\nService Account:  astronomy-shop\nNode:             kind-worker/192.168.97.2\nStart Time:       Tue, 19 Aug 2025 20:08:02 +0000\nLabels:           app.kubernetes.io/component=flagd\n                  app.kubernetes.io/name=flagd\n                  opentelemetry.io/name=flagd\n                  pod-template-hash=5854dbdc5d\nAnnotations:      kubectl.kubernetes.io/restartedAt: 2025-08-19T13:08:02-07:00\nStatus:           Running\nIP:               10.244.1.189\nIPs:\n  IP:           10.244.1.189\nControlled By:  ReplicaSet/flagd-5854dbdc5d\nInit Containers:\n  init-config:\n    Container ID:  containerd://cc8de075d9aae219dd512256d946de1e36c56c371b48d7c82ca84ced8d950d16\n    Image:         busybox\n    Image ID:      docker.io/library/busybox@sha256:ab33eacc8251e3807b85bb6dba570e4698c3998eca6f0fc2ccb60575a563ea74\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json\n    State:          Terminated\n      Reason:       Completed\n      Exit Code:    0\n      Started:      Tue, 19 Aug 2025 20:08:04 +0000\n      Finished:     Tue, 19 Aug 2025 20:08:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /config-ro from config-ro (rw)\n      /config-rw from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-c9z4b (ro)\nContainers:\n  flagd:\n    Container ID:  containerd://288e3db8ae115fa712bcf67bd7bdd03db43c80877e4f27298f0f0de87443339b\n    Image:         ghcr.io/open-feature/flagd:v0.12.8\n    Image ID:      ghcr.io/open-feature/flagd@sha256:634bd05995f5fd0a1b8196822feb8c2d99d37be9e2a25cb17b5d6c4c8fd7e821\n    Ports:         8013/TCP, 8016/TCP\n    Host Ports:    0/TCP, 0/TCP\n    Command:\n      /flagd-build\n      start\n      --port\n      8013\n      --ofrep-port\n      8016\n      --uri\n      file:./etc/flagd/demo.flagd.json\n    State:          Running\n      Started:      Tue, 19 Aug 2025 20:08:06 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  75Mi\n    Requests:\n      memory:  75Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      FLAGD_METRICS_EXPORTER:                             otel\n      FLAGD_OTEL_COLLECTOR_URI:                           $(OTEL_COLLECTOR_NAME):4317\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /etc/flagd from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-c9z4b (ro)\n  flagd-ui:\n    Container ID:   containerd://967bb49b13cbeec66bcb3c748d966ca2aad65cc9a3c1e69bce7027f5c05fc973\n    Image:          ghcr.io/open-telemetry/demo:2.0.2-flagd-ui\n    Image ID:       ghcr.io/open-telemetry/demo@sha256:655da6a8735b7bb7da2c36c8992387d03ae06420f2a06fbc499f2591889c1d03\n    Port:           4000/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Aug 2025 20:08:06 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  100Mi\n    Requests:\n      memory:  100Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      FLAGD_METRICS_EXPORTER:                             otel\n      OTEL_EXPORTER_OTLP_ENDPOINT:                        http://$(OTEL_COLLECTOR_NAME):4318\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /app/data from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-c9z4b (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  config-rw:\n    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n    Medium:     \n    SizeLimit:  <unset>\n  config-ro:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      flagd-config\n    Optional:  false\n  kube-api-access-c9z4b:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  11s   default-scheduler  Successfully assigned astronomy-shop/flagd-5854dbdc5d-flhts to kind-worker\n  Normal  Pulling    11s   kubelet            Pulling image \"busybox\"\n  Normal  Pulled     10s   kubelet            Successfully pulled image \"busybox\" in 1.002s (1.002s including waiting). Image size: 1913387 bytes.\n  Normal  Created    10s   kubelet            Created container: init-config\n  Normal  Started    10s   kubelet            Started container init-config\n  Normal  Pulled     8s    kubelet            Container image \"ghcr.io/open-feature/flagd:v0.12.8\" already present on machine\n  Normal  Created    8s    kubelet            Created container: flagd\n  Normal  Started    8s    kubelet            Started container flagd\n  Normal  Pulled     8s    kubelet            Container image \"ghcr.io/open-telemetry/demo:2.0.2-flagd-ui\" already present on machine\n  Normal  Created    8s    kubelet            Created container: flagd-ui\n  Normal  Started    8s    kubelet            Started container flagd-ui\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop otel-collector-758b8784c-4k2h5\")\n```"
        },
        {
            "role": "env",
            "content": "2025-08-19T20:07:30.339Z\tinfo\tservice@v0.131.0/service.go:214\tSetting up own telemetry...\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T20:07:30.349Z\tinfo\tmemorylimiter@v0.131.0/memorylimiter.go:149\tUsing percentage memory limiter\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.kind\": \"processor\", \"total_memory_mib\": 200, \"limit_percentage\": 80, \"spike_limit_percentage\": 25}\n2025-08-19T20:07:30.349Z\tinfo\tmemorylimiter@v0.131.0/memorylimiter.go:74\tMemory limiter configured\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.kind\": \"processor\", \"limit_mib\": 160, \"spike_limit_mib\": 50, \"check_interval\": 5}\n2025-08-19T20:07:30.350Z\tinfo\tspanmetricsconnector@v0.131.0/connector.go:114\tBuilding spanmetrics connector\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"spanmetrics\", \"otelcol.component.kind\": \"connector\", \"otelcol.signal\": \"traces\", \"otelcol.signal.output\": \"metrics\"}\n2025-08-19T20:07:30.352Z\tinfo\tottl@v0.131.0/parser_collection.go:646\tone or more paths were modified to include their context prefix, please rewrite them accordingly\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"transform\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"traces\", \"otelcol.signal\": \"traces\", \"values\": {\"[0]\": {\"original\": \"replace_pattern(name, \\\"\\\\\\\\?.*\\\", \\\"\\\")\", \"modified\": \"replace_pattern(span.name, \\\"\\\\\\\\?.*\\\", \\\"\\\")\"}, \"[1]\": {\"original\": \"replace_match(name, \\\"GET /api/products/*\\\", \\\"GET /api/products/{productId}\\\")\", \"modified\": \"replace_match(span.name, \\\"GET /api/products/*\\\", \\\"GET /api/products/{productId}\\\")\"}}}\n2025-08-19T20:07:30.357Z\tinfo\tbuilders/extension.go:50\tUnmaintained component. Actively looking for contributors. Component will become deprecated after 3 months of remaining unmaintained.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T20:07:30.358Z\tinfo\tservice@v0.131.0/service.go:276\tStarting otelcol-contrib...\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"Version\": \"0.131.0\", \"NumCPU\": 16}\n2025-08-19T20:07:30.358Z\tinfo\textensions/extensions.go:41\tStarting extensions...\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T20:07:30.358Z\tinfo\textensions/extensions.go:45\tExtension is starting...\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T20:07:30.358Z\tinfo\thealthcheckextension@v0.131.0/healthcheckextension.go:32\tStarting health_check extension\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\", \"config\": {\"Endpoint\":\"10.244.1.179:13133\",\"TLS\":{},\"CORS\":{},\"Auth\":{},\"MaxRequestBodySize\":0,\"IncludeMetadata\":false,\"ResponseHeaders\":null,\"CompressionAlgorithms\":null,\"ReadTimeout\":0,\"ReadHeaderTimeout\":0,\"WriteTimeout\":0,\"IdleTimeout\":0,\"Middlewares\":null,\"Path\":\"/\",\"ResponseBody\":null,\"CheckCollectorPipeline\":{\"Enabled\":false,\"Interval\":\"5m\",\"ExporterFailureThreshold\":5}}}\n2025-08-19T20:07:30.360Z\tinfo\textensions/extensions.go:62\tExtension started.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T20:07:30.371Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"metrics\", \"otelcol.signal\": \"metrics\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T20:07:30.371Z\tinfo\tspanmetricsconnector@v0.131.0/connector.go:207\tStarting spanmetrics connector\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"spanmetrics\", \"otelcol.component.kind\": \"connector\", \"otelcol.signal\": \"traces\", \"otelcol.signal.output\": \"metrics\"}\n2025-08-19T20:07:30.375Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"traces\", \"otelcol.signal\": \"traces\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T20:07:30.392Z\tinfo\totlpreceiver@v0.131.0/otlp.go:117\tStarting GRPC server\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlp\", \"otelcol.component.kind\": \"receiver\", \"endpoint\": \"10.244.1.179:4317\"}\n2025-08-19T20:07:30.398Z\tinfo\totlpreceiver@v0.131.0/otlp.go:175\tStarting HTTP server\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlp\", \"otelcol.component.kind\": \"receiver\", \"endpoint\": \"10.244.1.179:4318\"}\n2025-08-19T20:07:30.400Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T20:07:30.410Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:233\tStarting UDP server for Compact Thrift\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.179:6831\"}\n2025-08-19T20:07:30.415Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:337\tStarting HTTP server for Jaeger Thrift\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.179:14268\"}\n2025-08-19T20:07:30.416Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:362\tStarting gRPC server for Jaeger Protobuf\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.179:14250\"}\n2025-08-19T20:07:30.416Z\tinfo\thealthcheck/handler.go:131\tHealth Check state change\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\", \"status\": \"ready\"}\n2025-08-19T20:07:30.416Z\tinfo\tservice@v0.131.0/service.go:299\tEverything is ready. Begin running and processing data.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T20:07:30.490Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #2 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: \"jaeger-collector:4317\", ServerName: \"jaeger-collector:4317\", }. Err: connection error: desc = \"transport: Error while dialing: dial tcp: lookup jaeger-collector on 10.96.0.10:53: no such host\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:31.574Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 2, \"metrics\": 28, \"data points\": 37}\n2025-08-19T20:07:31.579Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"6.880928504s\"}\n2025-08-19T20:07:31.780Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T20:07:32.238Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.003188755, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:32.242Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 4}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:32.243Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 4}\n2025-08-19T20:07:32.244Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:33.183Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 3, \"data points\": 4}\n2025-08-19T20:07:33.186Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"6.476175411s\"}\n2025-08-19T20:07:33.186Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T20:07:33.253Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.001018918, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:33.255Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 4}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:33.255Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 4}\n2025-08-19T20:07:33.255Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:33.387Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 12, \"spans\": 52}\n2025-08-19T20:07:33.457Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000546876, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:33.457Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 2}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:33.458Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T20:07:33.458Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:33.588Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 35}\n2025-08-19T20:07:33.989Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 63}\n2025-08-19T20:07:34.189Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T20:07:34.396Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.004865882, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:34.408Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 59}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:34.408Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 8, \"log records\": 59}\n2025-08-19T20:07:34.408Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:34.591Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 2}\n2025-08-19T20:07:34.992Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 13}\n2025-08-19T20:07:35.208Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 19}\n2025-08-19T20:07:35.215Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000514876, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:35.215Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 2}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:35.215Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 2}\n2025-08-19T20:07:35.215Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:35.410Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 27}\n2025-08-19T20:07:35.819Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000983043, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:35.820Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 10}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:35.820Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 10}\n2025-08-19T20:07:35.820Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:36.024Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.001661252, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:36.029Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 1}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:36.029Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:36.029Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:36.233Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000656001, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:36.233Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 46}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:36.233Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 10, \"log records\": 46}\n2025-08-19T20:07:36.233Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:37.065Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000891168, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:37.065Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 5}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:37.065Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 5, \"log records\": 5}\n2025-08-19T20:07:37.065Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:38.271Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 1.003982455, \"reason\": \"dial tcp 10.96.100.91:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:38.271Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\", \"rejected_items\": 25}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:07:38.271Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 7, \"log records\": 25}\n2025-08-19T20:07:38.271Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.100.91:9200: connect: connection refused\"}\n2025-08-19T20:07:39.494Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"4.817467391s\"}\n2025-08-19T20:07:39.666Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"10.510213135s\"}\n2025-08-19T20:07:40.508Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:41.468Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:07:41.487Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"6.701179938s\"}\n2025-08-19T20:07:41.515Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:41.877Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 24}\n2025-08-19T20:07:42.279Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 20}\n2025-08-19T20:07:42.676Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 21}\n2025-08-19T20:07:42.685Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 49}\n2025-08-19T20:07:43.086Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T20:07:43.086Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:43.290Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T20:07:43.299Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 7, \"log records\": 8}\n2025-08-19T20:07:43.491Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T20:07:43.692Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 20}\n2025-08-19T20:07:43.894Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 27}\n2025-08-19T20:07:43.916Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T20:07:44.095Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T20:07:44.171Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 52}\n2025-08-19T20:07:44.296Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 40}\n2025-08-19T20:07:44.328Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"9.597715392s\"}\n2025-08-19T20:07:44.387Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:44.987Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 342}\n2025-08-19T20:07:45.223Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 13, \"log records\": 62}\n2025/08/19 20:07:45 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:07:45.447Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:45.553Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:45.945Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 174}\n2025-08-19T20:07:46.225Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 8, \"log records\": 17}\n2025-08-19T20:07:48.198Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"10.414547671s\"}\n2025-08-19T20:07:50.210Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"6.266200163s\"}\n2025-08-19T20:07:50.223Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:51.570Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:07:51.604Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"5.792120539s\"}\n2025-08-19T20:07:51.998Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T20:07:52.200Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 35}\n2025-08-19T20:07:52.402Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T20:07:52.603Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T20:07:52.804Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 12, \"spans\": 107}\n2025-08-19T20:07:52.810Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 16}\n2025-08-19T20:07:53.015Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T20:07:53.217Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 10, \"spans\": 42}\n2025-08-19T20:07:53.239Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 67}\n2025-08-19T20:07:53.418Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 34}\n2025-08-19T20:07:53.620Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T20:07:53.823Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 62}\n2025-08-19T20:07:53.945Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:53.960Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"20.488733031s\"}\n2025-08-19T20:07:54.204Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 34}\n2025-08-19T20:07:54.834Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:55.267Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 13, \"log records\": 41}\n2025/08/19 20:07:55 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:07:55.891Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 4}\n2025-08-19T20:07:56.108Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:56.395Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 27}\n2025-08-19T20:07:56.522Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"22.518245648s\"}\n2025-08-19T20:07:56.705Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:07:57.554Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"6.127308918s\"}\n2025-08-19T20:07:57.683Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:07:58.758Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.230.125:9090: connect: connection refused\", \"interval\": \"8.409677145s\"}\n2025-08-19T20:08:03.540Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T20:08:05.680Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 11}\n2025/08/19 20:08:06 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:08:08.608Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 10, \"spans\": 557}\n2025-08-19T20:08:10.015Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:08:14.887Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T20:08:15.316Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.98.172:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:08:20.786Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 17, \"spans\": 189}\n2025-08-19T20:08:24.712Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"838e0551-257d-46e1-9ecd-bebd17ba2052\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 55}\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop prometheus-58b7bfb774-s6bm9\")\n```"
        },
        {
            "role": "env",
            "content": "time=2025-08-19T20:07:29.766Z level=INFO source=main.go:228 msg=\"Experimental in-memory exemplar storage enabled\"\ntime=2025-08-19T20:07:29.775Z level=INFO source=main.go:1544 msg=\"updated GOGC\" old=100 new=75\ntime=2025-08-19T20:07:29.775Z level=INFO source=main.go:676 msg=\"Leaving GOMAXPROCS=16: CPU quota undefined\" component=automaxprocs\ntime=2025-08-19T20:07:29.775Z level=INFO source=memlimit.go:198 msg=\"GOMEMLIMIT is updated\" component=automemlimit package=github.com/KimMachineGun/automemlimit/memlimit GOMEMLIMIT=283115520 previous=9223372036854775807\ntime=2025-08-19T20:07:29.775Z level=INFO source=main.go:769 msg=\"Starting Prometheus Server\" mode=server version=\"(version=3.5.0, branch=HEAD, revision=8be3a9560fbdd18a94dedec4b747c35178177202)\"\ntime=2025-08-19T20:07:29.775Z level=INFO source=main.go:774 msg=\"operational information\" build_context=\"(go=go1.24.5, platform=linux/arm64, user=root@4451b64cb451, date=20250714-16:18:17, tags=netgo,builtinassets)\" host_details=\"(Linux 6.14.10-orbstack-00291-g1b252bd3edea #1 SMP Sat Jun  7 02:45:18 UTC 2025 aarch64 prometheus-58b7bfb774-s6bm9 (none))\" fd_limits=\"(soft=1073741816, hard=1073741816)\" vm_limits=\"(soft=unlimited, hard=unlimited)\"\ntime=2025-08-19T20:07:29.780Z level=INFO source=web.go:656 msg=\"Start listening for connections\" component=web address=0.0.0.0:9090\ntime=2025-08-19T20:07:29.781Z level=INFO source=main.go:1288 msg=\"Starting TSDB ...\"\ntime=2025-08-19T20:07:29.783Z level=INFO source=tls_config.go:347 msg=\"Listening on\" component=web address=[::]:9090\ntime=2025-08-19T20:07:29.783Z level=INFO source=tls_config.go:350 msg=\"TLS is disabled.\" component=web http2=false address=[::]:9090\ntime=2025-08-19T20:07:29.817Z level=INFO source=head.go:657 msg=\"Replaying on-disk memory mappable chunks if any\" component=tsdb\ntime=2025-08-19T20:07:29.817Z level=INFO source=head.go:744 msg=\"On-disk memory mappable chunks replay completed\" component=tsdb duration=750ns\ntime=2025-08-19T20:07:29.817Z level=INFO source=head.go:752 msg=\"Replaying WAL, this may take a while\" component=tsdb\ntime=2025-08-19T20:07:29.818Z level=INFO source=head.go:825 msg=\"WAL segment loaded\" component=tsdb segment=0 maxSegment=0 duration=262.25\u00b5s\ntime=2025-08-19T20:07:29.819Z level=INFO source=head.go:853 msg=\"WBL segment loaded\" component=tsdb segment=0 maxSegment=0\ntime=2025-08-19T20:07:29.819Z level=INFO source=head.go:862 msg=\"WAL replay completed\" component=tsdb checkpoint_replay_duration=1.183668ms wal_replay_duration=280.958\u00b5s wbl_replay_duration=1.033418ms chunk_snapshot_load_duration=0s mmap_chunk_replay_duration=750ns total_replay_duration=2.507753ms\ntime=2025-08-19T20:07:29.825Z level=INFO source=main.go:1309 msg=\"filesystem information\" fs_type=9123683e\ntime=2025-08-19T20:07:29.825Z level=INFO source=main.go:1312 msg=\"TSDB started\"\ntime=2025-08-19T20:07:29.825Z level=INFO source=main.go:1497 msg=\"Loading configuration file\" filename=/etc/config/prometheus.yml\ntime=2025-08-19T20:07:29.826Z level=INFO source=kubernetes.go:312 msg=\"Using pod service account via in-cluster config\" component=\"discovery manager scrape\" discovery=kubernetes config=kubernetes-apiservers\ntime=2025-08-19T20:07:29.827Z level=INFO source=kubernetes.go:312 msg=\"Using pod service account via in-cluster config\" component=\"discovery manager scrape\" discovery=kubernetes config=kubernetes-nodes\ntime=2025-08-19T20:07:29.827Z level=INFO source=kubernetes.go:312 msg=\"Using pod service account via in-cluster config\" component=\"discovery manager scrape\" discovery=kubernetes config=kubernetes-pods\ntime=2025-08-19T20:07:29.828Z level=INFO source=kubernetes.go:312 msg=\"Using pod service account via in-cluster config\" component=\"discovery manager scrape\" discovery=kubernetes config=prometheus-pushgateway\ntime=2025-08-19T20:07:29.828Z level=INFO source=main.go:1537 msg=\"Completed loading of configuration file\" db_storage=1.042\u00b5s remote_storage=1.208\u00b5s web_handler=500ns query_engine=1.333\u00b5s scrape=186.5\u00b5s scrape_sd=1.622085ms notify=1.042\u00b5s notify_sd=333ns rules=134.875\u00b5s tracing=2.208\u00b5s filename=/etc/config/prometheus.yml totalDuration=2.795254ms\ntime=2025-08-19T20:07:29.828Z level=INFO source=main.go:1273 msg=\"Server is ready to receive web requests.\"\ntime=2025-08-19T20:07:29.829Z level=INFO source=manager.go:176 msg=\"Starting rule manager...\" component=\"rule manager\"\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop opensearch-0\")\n```"
        },
        {
            "role": "env",
            "content": "Defaulted container \"opensearch\" out of: opensearch, configfile (init)\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop opensearch-0 -c opensearch\")\n```"
        },
        {
            "role": "env",
            "content": "Disabling OpenSearch Security Plugin\nEnabling execution of OPENSEARCH_HOME/bin/opensearch-performance-analyzer/performance-analyzer-agent-cli for OpenSearch Performance Analyzer Plugin\nWARNING: Using incubator modules: jdk.incubator.vector\nWARNING: A terminally deprecated method in java.lang.System has been called\nWARNING: System::setSecurityManager has been called by org.opensearch.bootstrap.OpenSearch (file:/usr/share/opensearch/lib/opensearch-2.19.3.jar)\nWARNING: Please consider reporting this to the maintainers of org.opensearch.bootstrap.OpenSearch\nWARNING: System::setSecurityManager will be removed in a future release\nAug 19, 2025 8:07:31 PM sun.util.locale.provider.LocaleProviderAdapter <clinit>\nWARNING: COMPAT locale provider will be removed in a future release\nWARNING: A terminally deprecated method in java.lang.System has been called\nWARNING: System::setSecurityManager has been called by org.opensearch.bootstrap.Security (file:/usr/share/opensearch/lib/opensearch-2.19.3.jar)\nWARNING: Please consider reporting this to the maintainers of org.opensearch.bootstrap.Security\nWARNING: System::setSecurityManager will be removed in a future release\n[2025-08-19T20:07:31,884][INFO ][o.o.n.Node               ] [opensearch-0] version[2.19.3], pid[1], build[tar/a90f864b8524bc75570a8461ccb569d2a4bfed42/2025-07-21T22:34:54.259463448Z], OS[Linux/6.14.10-orbstack-00291-g1b252bd3edea/aarch64], JVM[Eclipse Adoptium/OpenJDK 64-Bit Server VM/21.0.7/21.0.7+6-LTS]\n[2025-08-19T20:07:31,885][INFO ][o.o.n.Node               ] [opensearch-0] JVM home [/usr/share/opensearch/jdk], using bundled JDK/JRE [true]\n[2025-08-19T20:07:31,885][INFO ][o.o.n.Node               ] [opensearch-0] JVM arguments [-Xshare:auto, -Dopensearch.networkaddress.cache.ttl=60, -Dopensearch.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.security.manager=allow, -Djava.locale.providers=SPI,COMPAT, -Xms1g, -Xmx1g, -XX:+UseG1GC, -XX:G1ReservePercent=25, -XX:InitiatingHeapOccupancyPercent=30, -Djava.io.tmpdir=/tmp/opensearch-16103113162452992870, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.security.manager=allow, --add-modules=jdk.incubator.vector, -Djava.util.concurrent.ForkJoinPool.common.threadFactory=org.opensearch.secure_sm.SecuredForkJoinWorkerThreadFactory, -Dclk.tck=100, -Djdk.attach.allowAttachSelf=true, -Djava.security.policy=/usr/share/opensearch/config/opensearch-performance-analyzer/opensearch_security.policy, --add-opens=jdk.attach/sun.tools.attach=ALL-UNNAMED, -Dopensearch.cgroups.hierarchy.override=/, -Xms300m, -Xmx300m, -XX:MaxDirectMemorySize=157286400, -Dopensearch.path.home=/usr/share/opensearch, -Dopensearch.path.conf=/usr/share/opensearch/config, -Dopensearch.distribution.type=tar, -Dopensearch.bundled_jdk=true]\n[2025-08-19T20:07:31,987][INFO ][o.a.l.i.v.PanamaVectorizationProvider] [opensearch-0] Java vector incubator API enabled; uses preferredBitSize=128; FMA enabled\n[2025-08-19T20:07:32,597][INFO ][o.o.s.s.t.SSLConfig      ] [opensearch-0] SSL dual mode is disabled\n[2025-08-19T20:07:32,598][WARN ][o.o.s.OpenSearchSecurityPlugin] [opensearch-0] OpenSearch Security plugin installed but disabled. This can expose your configuration (including passwords) to the public.\n[2025-08-19T20:07:33,133][INFO ][o.o.p.c.c.PluginSettings ] [opensearch-0] Trying to create directory /dev/shm/performanceanalyzer/.\n[2025-08-19T20:07:33,133][INFO ][o.o.p.c.c.PluginSettings ] [opensearch-0] Config: metricsLocation: /dev/shm/performanceanalyzer/, metricsDeletionInterval: 1, httpsEnabled: false, cleanup-metrics-db-files: true, batch-metrics-retention-period-minutes: 7, rpc-port: 9650, webservice-port 9600\n[2025-08-19T20:07:33,468][INFO ][o.o.i.r.ReindexPlugin    ] [opensearch-0] ReindexPlugin reloadSPI called\n[2025-08-19T20:07:33,469][INFO ][o.o.i.r.ReindexPlugin    ] [opensearch-0] Unable to find any implementation for RemoteReindexExtension\n[2025-08-19T20:07:33,482][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: opensearch_time_series_analytics, index: .opendistro-anomaly-detector-jobs\n[2025-08-19T20:07:33,492][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: reports-scheduler, index: .opendistro-reports-definitions\n[2025-08-19T20:07:33,493][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: opendistro-index-management, index: .opendistro-ism-config\n[2025-08-19T20:07:33,494][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: checkBatchJobTaskStatus, index: .ml_commons_task_polling_job\n[2025-08-19T20:07:33,495][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: scheduler_geospatial_ip2geo_datasource, index: .scheduler-geospatial-ip2geo-datasource\n[2025-08-19T20:07:33,495][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: opensearch_sap_job, index: .opensearch-sap--job\n[2025-08-19T20:07:33,496][INFO ][o.o.j.JobSchedulerPlugin ] [opensearch-0] Loaded scheduler extension: async-query-scheduler, index: .async-query-scheduler\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [aggs-matrix-stats]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [analysis-common]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [cache-common]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [geo]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [ingest-common]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [ingest-geoip]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [ingest-user-agent]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [lang-expression]\n[2025-08-19T20:07:33,507][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [lang-mustache]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [lang-painless]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [mapper-extras]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [opensearch-dashboards]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [parent-join]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [percolator]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [rank-eval]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [reindex]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [repository-url]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [search-pipeline-common]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [systemd]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded module [transport-netty4]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-alerting]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-anomaly-detection]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-asynchronous-search]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-cross-cluster-replication]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-custom-codecs]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-flow-framework]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-geospatial]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-index-management]\n[2025-08-19T20:07:33,508][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-job-scheduler]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-knn]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-ltr]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-ml]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-neural-search]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-notifications]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-notifications-core]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-observability]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-performance-analyzer]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-reports-scheduler]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-security]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-security-analytics]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-skills]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-sql]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [opensearch-system-templates]\n[2025-08-19T20:07:33,509][INFO ][o.o.p.PluginsService     ] [opensearch-0] loaded plugin [query-insights]\n[2025-08-19T20:07:33,575][WARN ][stderr                   ] [opensearch-0] WARNING: A restricted method in java.lang.foreign.Linker has been called\n[2025-08-19T20:07:33,576][WARN ][stderr                   ] [opensearch-0] WARNING: java.lang.foreign.Linker::downcallHandle has been called by the unnamed module\n[2025-08-19T20:07:33,576][WARN ][stderr                   ] [opensearch-0] WARNING: Use --enable-native-access=ALL-UNNAMED to avoid a warning for this module\n[2025-08-19T20:07:33,629][INFO ][o.a.l.s.MemorySegmentIndexInputProvider] [opensearch-0] Using MemorySegmentIndexInput and native madvise support with Java 21 or later; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n[2025-08-19T20:07:33,633][INFO ][o.o.e.NodeEnvironment    ] [opensearch-0] using [1] data paths, mounts [[/ (overlay)]], net usable_space [300.6gb], net total_space [338.5gb], types [overlay]\n[2025-08-19T20:07:33,633][INFO ][o.o.e.NodeEnvironment    ] [opensearch-0] heap size [300mb], compressed ordinary object pointers [true]\n[2025-08-19T20:07:33,637][DEPRECATION][o.o.d.c.n.DiscoveryNodeRole] [opensearch-0] Assigning [master] role in setting [node.roles] is deprecated. To promote inclusive language, please use [cluster_manager] role instead.\n[2025-08-19T20:07:33,657][INFO ][o.o.n.Node               ] [opensearch-0] node name [opensearch-0], node ID [9K_hng0vS52Xg0eF-pvm1w], cluster name [demo-cluster], roles [ingest, remote_cluster_client, master, data]\n[2025-08-19T20:07:33,683][INFO ][o.o.e.ExtensionsManager  ] [opensearch-0] ExtensionsManager initialized\n[2025-08-19T20:07:34,967][DEPRECATION][o.o.d.c.s.Settings       ] [opensearch-0] [index.store.hybrid.mmap.extensions] setting was deprecated in OpenSearch and will be removed in a future release! See the breaking changes documentation for the next major version.\n[2025-08-19T20:07:35,544][INFO ][o.o.n.p.NeuralSearch     ] [opensearch-0] Registering hybrid query phase searcher with feature flag [plugins.neural_search.hybrid_search_disabled]\n[2025-08-19T20:07:35,969][INFO ][o.o.l.b.LTRCircuitBreakerService] [opensearch-0] Registered memory breaker.\n[2025-08-19T20:07:36,047][INFO ][o.o.t.b.CircuitBreakerService] [opensearch-0] Registered memory breaker.\n[2025-08-19T20:07:36,214][INFO ][o.o.r.m.c.i.SdkClientFactory] [opensearch-0] Using local opensearch cluster as metadata store.\n[2025-08-19T20:07:36,306][INFO ][o.o.r.m.c.i.SdkClientFactory] [opensearch-0] Using local opensearch cluster as metadata store.\n[2025-08-19T20:07:36,319][INFO ][o.o.m.b.MLCircuitBreakerService] [opensearch-0] Registered ML memory breaker.\n[2025-08-19T20:07:36,320][INFO ][o.o.m.b.MLCircuitBreakerService] [opensearch-0] Registered ML disk breaker.\n[2025-08-19T20:07:36,320][INFO ][o.o.m.b.MLCircuitBreakerService] [opensearch-0] Registered ML native memory breaker.\n[2025-08-19T20:07:36,384][INFO ][o.r.Reflections          ] [opensearch-0] Reflections took 39 ms to scan 1 urls, producing 27 keys and 67 values \n[2025-08-19T20:07:36,402][INFO ][o.r.Reflections          ] [opensearch-0] Reflections took 2 ms to scan 1 urls, producing 3 keys and 5 values \n[2025-08-19T20:07:36,534][WARN ][o.o.s.p.SQLPlugin        ] [opensearch-0] Master key is a required config for using create and update datasource APIs. Please set plugins.query.datasources.encryption.masterkey config in opensearch.yml in all the cluster nodes. More details can be found here: https://github.com/opensearch-project/sql/blob/main/docs/user/ppl/admin/datasources.rst#master-key-config-for-encrypting-credential-information\n[2025-08-19T20:07:36,716][INFO ][o.o.p.i.c.s.QueryInsightsService] [opensearch-0] Setting query insights index template priority to [1847]\n[2025-08-19T20:07:37,119][INFO ][o.o.t.NettyAllocator     ] [opensearch-0] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={opensearch.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=300mb}]\n[2025-08-19T20:07:37,199][INFO ][o.o.d.DiscoveryModule    ] [opensearch-0] using discovery type [single-node] and seed hosts providers [settings]\n[2025-08-19T20:07:37,600][WARN ][o.o.g.DanglingIndicesState] [opensearch-0] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually\n[2025-08-19T20:07:38,021][INFO ][o.o.p.h.c.PerformanceAnalyzerConfigAction] [opensearch-0] PerformanceAnalyzer Enabled: false\n[2025-08-19T20:07:38,052][INFO ][o.o.n.Node               ] [opensearch-0] initialized\n[2025-08-19T20:07:38,052][INFO ][o.o.n.Node               ] [opensearch-0] starting ...\n[2025-08-19T20:07:38,073][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [windows_logtype.json] log type\n[2025-08-19T20:07:38,073][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [waf_logtype.json] log type\n[2025-08-19T20:07:38,073][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [vpcflow_logtype.json] log type\n[2025-08-19T20:07:38,074][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [test_windows_logtype.json] log type\n[2025-08-19T20:07:38,074][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [s3_logtype.json] log type\n[2025-08-19T20:07:38,074][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_web_logtype.json] log type\n[2025-08-19T20:07:38,074][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_proxy_logtype.json] log type\n[2025-08-19T20:07:38,074][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_macos_logtype.json] log type\n[2025-08-19T20:07:38,074][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_compliance_logtype.json] log type\n[2025-08-19T20:07:38,075][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_cloud_logtype.json] log type\n[2025-08-19T20:07:38,075][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_apt_logtype.json] log type\n[2025-08-19T20:07:38,075][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [others_application_logtype.json] log type\n[2025-08-19T20:07:38,075][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [okta_logtype.json] log type\n[2025-08-19T20:07:38,075][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [network_logtype.json] log type\n[2025-08-19T20:07:38,075][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [netflow_logtype.json] log type\n[2025-08-19T20:07:38,076][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [m365_logtype.json] log type\n[2025-08-19T20:07:38,076][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [linux_logtype.json] log type\n[2025-08-19T20:07:38,076][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [gworkspace_logtype.json] log type\n[2025-08-19T20:07:38,076][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [github_logtype.json] log type\n[2025-08-19T20:07:38,076][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [dns_logtype.json] log type\n[2025-08-19T20:07:38,076][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [cloudtrail_logtype.json] log type\n[2025-08-19T20:07:38,077][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [azure_logtype.json] log type\n[2025-08-19T20:07:38,077][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [apache_access_logtype.json] log type\n[2025-08-19T20:07:38,077][INFO ][o.o.s.l.BuiltinLogTypeLoader] [opensearch-0] Loaded [ad_ldap_logtype.json] log type\n[2025-08-19T20:07:38,158][INFO ][o.o.t.TransportService   ] [opensearch-0] publish_address {10.244.1.178:9300}, bound_addresses {[::]:9300}\n[2025-08-19T20:07:38,159][INFO ][o.o.t.TransportService   ] [opensearch-0] Remote clusters initialized successfully.\n[2025-08-19T20:07:38,329][INFO ][o.o.c.c.Coordinator      ] [opensearch-0] setting initial configuration to VotingConfiguration{9K_hng0vS52Xg0eF-pvm1w}\n[2025-08-19T20:07:38,489][INFO ][o.o.c.s.MasterService    ] [opensearch-0] Tasks batched with key: org.opensearch.cluster.coordination.JoinHelper, count:3 and sample tasks: elected-as-cluster-manager ([1] nodes joined)[{opensearch-0}{9K_hng0vS52Xg0eF-pvm1w}{GEdJc4HTQBCYxpYKIX0NWA}{10.244.1.178}{10.244.1.178:9300}{dimr}{shard_indexing_pressure_enabled=true} elect leader, _BECOME_CLUSTER_MANAGER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, delta: cluster-manager node changed {previous [], current [{opensearch-0}{9K_hng0vS52Xg0eF-pvm1w}{GEdJc4HTQBCYxpYKIX0NWA}{10.244.1.178}{10.244.1.178:9300}{dimr}{shard_indexing_pressure_enabled=true}]}\n[2025-08-19T20:07:38,538][INFO ][o.o.c.c.CoordinationState] [opensearch-0] cluster UUID set to [rb83AO-NSTCRksnAd1WDvg]\n[2025-08-19T20:07:38,562][INFO ][o.o.c.s.ClusterApplierService] [opensearch-0] cluster-manager node changed {previous [], current [{opensearch-0}{9K_hng0vS52Xg0eF-pvm1w}{GEdJc4HTQBCYxpYKIX0NWA}{10.244.1.178}{10.244.1.178:9300}{dimr}{shard_indexing_pressure_enabled=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}\n[2025-08-19T20:07:38,566][INFO ][o.o.t.i.IndexManagement  ] [opensearch-0] Candidate custom result indices are empty.\n[2025-08-19T20:07:38,567][INFO ][o.o.t.i.IndexManagement  ] [opensearch-0] Candidate custom result indices are empty.\n[2025-08-19T20:07:38,567][INFO ][o.o.t.c.ClusterEventListener] [opensearch-0] Cluster is not recovered yet.\n[2025-08-19T20:07:38,589][INFO ][o.o.i.i.ManagedIndexCoordinator] [opensearch-0] Cache cluster manager node onClusterManager time: 1755634058589\n[2025-08-19T20:07:38,599][WARN ][o.o.p.c.s.h.ConfigOverridesClusterSettingHandler] [opensearch-0] Config override setting update called with empty string. Ignoring.\n[2025-08-19T20:07:38,613][INFO ][o.o.d.PeerFinder         ] [opensearch-0] setting findPeersInterval to [1s] as node commission status = [true] for local node [{opensearch-0}{9K_hng0vS52Xg0eF-pvm1w}{GEdJc4HTQBCYxpYKIX0NWA}{10.244.1.178}{10.244.1.178:9300}{dimr}{shard_indexing_pressure_enabled=true}]\n[2025-08-19T20:07:38,616][INFO ][o.o.h.AbstractHttpServerTransport] [opensearch-0] publish_address {10.244.1.178:9200}, bound_addresses {[::]:9200}\n[2025-08-19T20:07:38,616][INFO ][o.o.n.Node               ] [opensearch-0] started\n[2025-08-19T20:07:38,617][INFO ][o.o.s.OpenSearchSecurityPlugin] [opensearch-0] 0 OpenSearch Security modules loaded so far: []\n[2025-08-19T20:07:38,639][INFO ][o.o.t.c.HashRing         ] [opensearch-0] Node added: [9K_hng0vS52Xg0eF-pvm1w]\n[2025-08-19T20:07:38,644][INFO ][o.o.t.c.HashRing         ] [opensearch-0] Add data node to version hash ring: 9K_hng0vS52Xg0eF-pvm1w\n[2025-08-19T20:07:38,648][INFO ][o.o.t.c.HashRing         ] [opensearch-0] All nodes with known version: {9K_hng0vS52Xg0eF-pvm1w=ADNodeInfo{version=2.19.3, isEligibleDataNode=true}}\n[2025-08-19T20:07:38,648][INFO ][o.o.t.c.HashRing         ] [opensearch-0] Rebuild hash ring for realtime with cooldown, nodeChangeEvents size 0\n[2025-08-19T20:07:38,648][INFO ][o.o.t.c.HashRing         ] [opensearch-0] Build version hash ring successfully\n[2025-08-19T20:07:38,649][INFO ][o.o.t.c.ADDataMigrator   ] [opensearch-0] Start migrating AD data\n[2025-08-19T20:07:38,649][INFO ][o.o.t.c.ADDataMigrator   ] [opensearch-0] AD job index doesn't exist, no need to migrate\n[2025-08-19T20:07:38,649][INFO ][o.o.t.c.ClusterEventListener] [opensearch-0] Init version hash ring successfully\n[2025-08-19T20:07:38,658][INFO ][o.o.g.GatewayService     ] [opensearch-0] recovered [0] indices into cluster_state\n[2025-08-19T20:07:38,676][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.opensearch-observability/1KdD9Gs2TXyZjB0si2wryA]\n[2025-08-19T20:07:38,753][INFO ][o.o.c.m.MetadataCreateIndexService] [opensearch-0] [.opensearch-observability] creating index, cause [api], templates [], shards [1]/[0]\n[2025-08-19T20:07:38,798][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.opensearch-observability/1KdD9Gs2TXyZjB0si2wryA]\n[2025-08-19T20:07:38,838][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.opensearch-sap-log-types-config/P1gs7IALS_WABGiuQ50xRg]\n[2025-08-19T20:07:38,844][INFO ][o.o.c.m.MetadataCreateIndexService] [opensearch-0] [.opensearch-sap-log-types-config] creating index, cause [auto(sap-logtype api)], templates [], shards [1]/[1]\n[2025-08-19T20:07:38,845][INFO ][o.o.c.r.a.AllocationService] [opensearch-0] updating number_of_replicas to [0] for indices [.opensearch-sap-log-types-config]\n[2025-08-19T20:07:38,898][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.opensearch-sap-log-types-config/P1gs7IALS_WABGiuQ50xRg]\n[2025-08-19T20:07:39,018][INFO ][o.o.o.i.ObservabilityIndex] [opensearch-0] observability:Index .opensearch-observability creation Acknowledged\n[2025-08-19T20:07:39,019][INFO ][o.o.c.r.a.AllocationService] [opensearch-0] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.opensearch-sap-log-types-config][0]]]).\n[2025-08-19T20:07:39,048][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loading builtin types!\n[2025-08-19T20:07:39,049][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [432] fieldMappingDocs from logTypes: 24\n[2025-08-19T20:07:39,137][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [432] fieldMappingDocs\n[2025-08-19T20:07:39,171][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.opensearch-sap-log-types-config/P1gs7IALS_WABGiuQ50xRg]\n[2025-08-19T20:07:39,182][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [.opensearch-sap-log-types-config/P1gs7IALS_WABGiuQ50xRg] update_mapping [_doc]\n[2025-08-19T20:07:39,295][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.opensearch-sap-log-types-config/P1gs7IALS_WABGiuQ50xRg]\n[2025-08-19T20:07:39,306][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [.opensearch-sap-log-types-config/P1gs7IALS_WABGiuQ50xRg] update_mapping [_doc]\n[2025-08-19T20:07:39,540][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:39,541][INFO ][o.o.c.m.MetadataCreateIndexService] [opensearch-0] [otel] creating index, cause [auto(bulk api)], templates [], shards [1]/[1]\n[2025-08-19T20:07:39,574][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:39,602][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loading builtin types!\n[2025-08-19T20:07:39,602][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [432] fieldMappingDocs from logTypes: 24\n[2025-08-19T20:07:39,607][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loading builtin types!\n[2025-08-19T20:07:39,608][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [432] fieldMappingDocs from logTypes: 24\n[2025-08-19T20:07:39,612][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] info deleteOldIndices\n[2025-08-19T20:07:39,621][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] No Old Correlation Indices to delete\n[2025-08-19T20:07:39,622][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] info deleteOldIndices\n[2025-08-19T20:07:39,622][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] No Old IOC Findings Indices to delete\n[2025-08-19T20:07:39,622][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [432] fieldMappingDocs\n[2025-08-19T20:07:39,624][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [432] fieldMappingDocs\n[2025-08-19T20:07:39,755][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loaded [432] field mapping docs successfully!\n[2025-08-19T20:07:39,799][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:39,811][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [23] customLogTypes\n[2025-08-19T20:07:39,823][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] create_mapping\n[2025-08-19T20:07:39,881][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:39,892][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:39,912][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loaded [432] field mapping docs successfully!\n[2025-08-19T20:07:39,922][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [23] customLogTypes\n[2025-08-19T20:07:39,965][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:39,965][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loaded [23] customLogType docs successfully!\n[2025-08-19T20:07:39,966][INFO ][o.o.s.SecurityAnalyticsPlugin] [opensearch-0] LogType config index successfully created and builtin log types loaded\n[2025-08-19T20:07:39,966][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loaded [432] field mapping docs successfully!\n[2025-08-19T20:07:39,974][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:39,976][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Indexing [23] customLogTypes\n[2025-08-19T20:07:40,052][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loaded [23] customLogType docs successfully!\n[2025-08-19T20:07:40,059][INFO ][o.o.s.l.LogTypeService   ] [opensearch-0] Loaded [23] customLogType docs successfully!\n[2025-08-19T20:07:40,097][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,106][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:40,124][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] info deleteOldIndices\n[2025-08-19T20:07:40,127][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] info deleteOldIndices\n[2025-08-19T20:07:40,127][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] No Old Finding Indices to delete\n[2025-08-19T20:07:40,128][INFO ][o.o.s.i.DetectorIndexManagementService] [opensearch-0] No Old Alert Indices to delete\n[2025-08-19T20:07:40,200][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,207][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:40,263][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,274][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:40,313][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,319][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:40,359][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,368][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:40,664][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,670][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:40,747][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:40,752][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:45,896][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:45,901][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:48,614][INFO ][o.o.m.a.MLModelAutoReDeployer] [opensearch-0] Index not found, not performing auto reloading!\n[2025-08-19T20:07:48,614][INFO ][o.o.m.c.MLCommonsClusterManagerEventListener] [opensearch-0] Starting ML sync up job...\n[2025-08-19T20:07:48,824][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:48,837][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:48,898][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:07:48,915][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:07:58,625][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.plugins-ml-config/T4ebXIm3RIOY5REIblHNcA]\n[2025-08-19T20:07:58,637][INFO ][o.o.c.m.MetadataCreateIndexService] [opensearch-0] [.plugins-ml-config] creating index, cause [api], templates [], shards [1]/[1]\n[2025-08-19T20:07:58,637][INFO ][o.o.c.r.a.AllocationService] [opensearch-0] updating number_of_replicas to [0] for indices [.plugins-ml-config]\n[2025-08-19T20:07:58,694][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[.plugins-ml-config/T4ebXIm3RIOY5REIblHNcA]\n[2025-08-19T20:07:58,777][INFO ][o.o.m.e.i.MLIndicesHandler] [opensearch-0] create index:.plugins-ml-config\n[2025-08-19T20:07:58,809][INFO ][o.o.m.c.MLSyncUpCron     ] [opensearch-0] ML configuration initialized successfully\n[2025-08-19T20:08:36,917][INFO ][o.o.p.PluginsService     ] [opensearch-0] PluginService:onIndexModule index:[otel/12MQgl_DR7WKoWwsAdqlBw]\n[2025-08-19T20:08:36,953][INFO ][o.o.c.m.MetadataMappingService] [opensearch-0] [otel/12MQgl_DR7WKoWwsAdqlBw] update_mapping [_doc]\n[2025-08-19T20:08:38,592][INFO ][o.o.i.i.ManagedIndexCoordinator] [opensearch-0] Performing move cluster state metadata.\n[2025-08-19T20:08:38,593][INFO ][o.o.i.i.MetadataService  ] [opensearch-0] ISM config index not exist, so we cancel the metadata migration job.\n[2025-08-19T20:08:38,593][INFO ][o.o.i.i.ManagedIndexCoordinator] [opensearch-0] Performing ISM template migration.\n[2025-08-19T20:08:38,594][INFO ][o.o.i.i.m.ISMTemplateService] [opensearch-0] Doing ISM template migration 1 time.\n[2025-08-19T20:08:38,594][INFO ][o.o.i.i.m.ISMTemplateService] [opensearch-0] Use 2025-08-19T19:07:38.589Z as migrating ISM template last_updated_time\n[2025-08-19T20:08:38,595][INFO ][o.o.i.i.m.ISMTemplateService] [opensearch-0] ISM templates: {}\n[2025-08-19T20:08:38,595][INFO ][o.o.i.i.m.ISMTemplateService] [opensearch-0] Policies to update: []\n[2025-08-19T20:08:38,614][INFO ][o.o.i.i.m.ISMTemplateService] [opensearch-0] Failure experienced when migrating ISM Template and update ISM policies: {}\n[2025-08-19T20:08:38,648][INFO ][o.o.c.s.ClusterSettings  ] [opensearch-0] updating [plugins.index_state_management.template_migration.control] from [0] to [-1]\n[2025-08-19T20:08:38,651][INFO ][o.o.i.i.m.ISMTemplateService] [opensearch-0] Successfully update template migration setting\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl get svc -n astronomy-shop -o wide\")\n```"
        },
        {
            "role": "env",
            "content": "NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                            AGE    SELECTOR\nad                    ClusterIP   10.96.80.116    <none>        8080/TCP                                                           103s   opentelemetry.io/name=ad\ncart                  ClusterIP   10.96.213.169   <none>        8080/TCP                                                           103s   opentelemetry.io/name=cart\ncheckout              ClusterIP   10.96.9.129     <none>        8080/TCP                                                           103s   opentelemetry.io/name=checkout\ncurrency              ClusterIP   10.96.204.71    <none>        8080/TCP                                                           103s   opentelemetry.io/name=currency\nemail                 ClusterIP   10.96.72.135    <none>        8080/TCP                                                           103s   opentelemetry.io/name=email\nflagd                 ClusterIP   10.96.201.245   <none>        8013/TCP,8016/TCP,4000/TCP                                         103s   opentelemetry.io/name=flagd\nfrontend              ClusterIP   10.96.189.139   <none>        8080/TCP                                                           103s   opentelemetry.io/name=frontend\nfrontend-proxy        ClusterIP   10.96.46.14     <none>        8080/TCP                                                           103s   opentelemetry.io/name=frontend-proxy\ngrafana               ClusterIP   10.96.9.24      <none>        80/TCP                                                             103s   app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=grafana\nimage-provider        ClusterIP   10.96.83.99     <none>        8081/TCP                                                           103s   opentelemetry.io/name=image-provider\njaeger-agent          ClusterIP   None            <none>        5775/UDP,5778/TCP,6831/UDP,6832/UDP                                103s   app.kubernetes.io/component=all-in-one,app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=jaeger\njaeger-collector      ClusterIP   None            <none>        9411/TCP,14250/TCP,14267/TCP,14268/TCP,4317/TCP,4318/TCP           103s   app.kubernetes.io/component=all-in-one,app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=jaeger\njaeger-query          ClusterIP   None            <none>        16686/TCP,16685/TCP                                                103s   app.kubernetes.io/component=all-in-one,app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=jaeger\nkafka                 ClusterIP   10.96.200.242   <none>        9092/TCP,9093/TCP                                                  103s   opentelemetry.io/name=kafka\nload-generator        ClusterIP   10.96.137.90    <none>        8089/TCP                                                           103s   opentelemetry.io/name=load-generator\nopensearch            ClusterIP   10.96.100.91    <none>        9200/TCP,9300/TCP,9600/TCP                                         103s   app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=opensearch\nopensearch-headless   ClusterIP   None            <none>        9200/TCP,9300/TCP,9600/TCP                                         103s   app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=opensearch\notel-collector        ClusterIP   10.96.98.172    <none>        6831/UDP,14250/TCP,14268/TCP,8888/TCP,4317/TCP,4318/TCP,9411/TCP   103s   app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=opentelemetry-collector,component=standalone-collector\npayment               ClusterIP   10.96.49.227    <none>        8080/TCP                                                           103s   opentelemetry.io/name=payment\nproduct-catalog       ClusterIP   10.96.217.212   <none>        8080/TCP                                                           103s   opentelemetry.io/name=product-catalog\nprometheus            ClusterIP   10.96.230.125   <none>        9090/TCP                                                           103s   app.kubernetes.io/component=server,app.kubernetes.io/instance=astronomy-shop,app.kubernetes.io/name=prometheus\nquote                 ClusterIP   10.96.144.103   <none>        8080/TCP                                                           103s   opentelemetry.io/name=quote\nrecommendation        ClusterIP   10.96.8.234     <none>        8080/TCP                                                           103s   opentelemetry.io/name=recommendation\nshipping              ClusterIP   10.96.126.107   <none>        8080/TCP                                                           103s   opentelemetry.io/name=shipping\nvalkey-cart           ClusterIP   10.96.116.181   <none>        6379/TCP                                                           103s   opentelemetry.io/name=valkey-cart\n"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl get endpoints -n astronomy-shop -o wide\")\n```"
        },
        {
            "role": "env",
            "content": "NAME                  ENDPOINTS                                                            AGE\nad                    10.244.1.170:8080                                                    2m41s\ncart                  10.244.1.166:8080                                                    2m41s\ncheckout              10.244.1.185:8080                                                    2m41s\ncurrency              10.244.1.188:8080                                                    2m41s\nemail                 10.244.1.169:8080                                                    2m41s\nflagd                 10.244.1.189:8016,10.244.1.189:8013,10.244.1.189:4000                2m41s\nfrontend              10.244.1.180:8080                                                    2m41s\nfrontend-proxy        10.244.1.184:8080                                                    2m41s\ngrafana               10.244.1.165:3000                                                    2m41s\nimage-provider        10.244.1.183:8081                                                    2m41s\njaeger-agent          10.244.1.187:5778,10.244.1.187:5775,10.244.1.187:6832 + 1 more...    2m41s\njaeger-collector      10.244.1.187:4317,10.244.1.187:14268,10.244.1.187:4318 + 3 more...   2m41s\njaeger-query          10.244.1.187:16685,10.244.1.187:16686                                2m41s\nkafka                 10.244.1.177:9092,10.244.1.177:9093                                  2m41s\nload-generator        10.244.1.171:8089                                                    2m41s\nopensearch            10.244.1.178:9600,10.244.1.178:9200,10.244.1.178:9300                2m41s\nopensearch-headless   10.244.1.178:9600,10.244.1.178:9200,10.244.1.178:9300                2m41s\notel-collector        10.244.1.179:9411,10.244.1.179:4317,10.244.1.179:14268 + 4 more...   2m41s\npayment               10.244.1.176:8080                                                    2m41s\nproduct-catalog                                                                            2m41s\nprometheus            10.244.1.173:9090                                                    2m41s\nquote                 10.244.1.186:8080                                                    2m41s\nrecommendation        10.244.1.182:8080                                                    2m41s\nshipping              10.244.1.175:8080                                                    2m41s\nvalkey-cart           10.244.1.181:6379                                                    2m41s\n"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl describe pod product-catalog-6988cd5f49-v8xnv -n astronomy-shop\")\n```"
        },
        {
            "role": "env",
            "content": "Name:             product-catalog-6988cd5f49-v8xnv\nNamespace:        astronomy-shop\nPriority:         0\nService Account:  astronomy-shop\nNode:             kind-worker/192.168.97.2\nStart Time:       Tue, 19 Aug 2025 20:07:28 +0000\nLabels:           app.kubernetes.io/component=product-catalog\n                  app.kubernetes.io/name=product-catalog\n                  opentelemetry.io/name=product-catalog\n                  pod-template-hash=6988cd5f49\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.168\nIPs:\n  IP:           10.244.1.168\nControlled By:  ReplicaSet/product-catalog-6988cd5f49\nContainers:\n  product-catalog:\n    Container ID:   containerd://c5b4c8fee02a6465aba825017525b34c8e83f45f142db718aef5506a85ff0e76\n    Image:          ghcr.io/open-telemetry/demo:2.0.2-product-catalog\n    Image ID:       ghcr.io/open-telemetry/demo@sha256:050a0fc2026b75cc8716cbd5daf9c9e5fd552808a59928a6bfca18bfb8edd2d5\n    Port:           8080/TCP\n    Host Port:      0/TCP\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       OOMKilled\n      Exit Code:    137\n      Started:      Tue, 19 Aug 2025 20:17:24 +0000\n      Finished:     Tue, 19 Aug 2025 20:19:07 +0000\n    Ready:          False\n    Restart Count:  6\n    Limits:\n      memory:  20Mi\n    Requests:\n      memory:  20Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      PRODUCT_CATALOG_PORT:                               8080\n      PRODUCT_CATALOG_RELOAD_INTERVAL:                    10\n      FLAGD_HOST:                                         flagd\n      FLAGD_PORT:                                         8013\n      OTEL_EXPORTER_OTLP_ENDPOINT:                        http://$(OTEL_COLLECTOR_NAME):4317\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /usr/src/app/products from product-catalog-products (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-hbps8 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       False \n  ContainersReady             False \n  PodScheduled                True \nVolumes:\n  product-catalog-products:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      product-catalog-products\n    Optional:  false\n  kube-api-access-hbps8:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason            Age                  From               Message\n  ----     ------            ----                 ----               -------\n  Warning  FailedScheduling  12m                  default-scheduler  0/2 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) had untolerated taint {node.kubernetes.io/unreachable: }. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.\n  Normal   Scheduled         12m                  default-scheduler  Successfully assigned astronomy-shop/product-catalog-6988cd5f49-v8xnv to kind-worker\n  Normal   Pulled            2m17s (x7 over 12m)  kubelet            Container image \"ghcr.io/open-telemetry/demo:2.0.2-product-catalog\" already present on machine\n  Normal   Created           2m17s (x7 over 12m)  kubelet            Created container: product-catalog\n  Normal   Started           2m17s (x7 over 12m)  kubelet            Started container product-catalog\n  Warning  BackOff           19s (x27 over 10m)   kubelet            Back-off restarting failed container product-catalog in pod product-catalog-6988cd5f49-v8xnv_astronomy-shop(0deb47ab-9526-4726-af33-32d3b3d5159c)\n"
        },
        {
            "role": "assistant",
            "content": "```\nsubmit([\"product-catalog\"])\n```"
        },
        {
            "role": "env",
            "content": "1"
        }
    ],
    "results": {
        "Localization Accuracy": 0.0,
        "TTL": 721.5554840564728,
        "steps": 27,
        "in_tokens": 53368,
        "out_tokens": 210,
        "success": false,
        "is_subset": false
    }
}