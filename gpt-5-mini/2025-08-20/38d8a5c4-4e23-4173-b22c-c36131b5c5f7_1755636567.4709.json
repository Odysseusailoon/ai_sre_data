{
    "agent": "gpt-w-shell",
    "session_id": "38d8a5c4-4e23-4173-b22c-c36131b5c5f7",
    "problem_id": "astronomy_shop_product_catalog_service_failure-localization-1",
    "start_time": 1755636567.4709,
    "end_time": 1755636647.9702778,
    "trace": [
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl get pods -n astronomy-shop -o wide\")\n```"
        },
        {
            "role": "env",
            "content": "NAME                               READY   STATUS     RESTARTS      AGE   IP             NODE          NOMINATED NODE   READINESS GATES\naccounting-567f87bbcd-9rpbv        1/1     Running    0             35s   10.244.1.218   kind-worker   <none>           <none>\nad-856c77f595-q76m6                1/1     Running    0             34s   10.244.1.220   kind-worker   <none>           <none>\ncart-6fd857c656-hzq98              1/1     Running    0             35s   10.244.1.215   kind-worker   <none>           <none>\ncheckout-5bc54f8cd8-nr592          1/1     Running    0             35s   10.244.1.209   kind-worker   <none>           <none>\ncurrency-5864f94d89-xvd5c          1/1     Running    0             35s   10.244.1.216   kind-worker   <none>           <none>\nemail-59d9ffc758-p9xgx             1/1     Running    0             35s   10.244.1.219   kind-worker   <none>           <none>\nflagd-5f7bcb686-dxs4b              0/2     Init:0/1   0             0s    <none>         kind-worker   <none>           <none>\nflagd-86575d5796-rxglj             2/2     Running    0             35s   10.244.1.211   kind-worker   <none>           <none>\nfraud-detection-65868bcdb5-8flhr   1/1     Running    0             35s   10.244.1.217   kind-worker   <none>           <none>\nfrontend-7d6b77c58-vfpls           1/1     Running    0             33s   10.244.1.227   kind-worker   <none>           <none>\nfrontend-proxy-548b4649d7-8dwdd    1/1     Running    0             34s   10.244.1.221   kind-worker   <none>           <none>\ngrafana-6b9fb84fb7-qp2sb           1/1     Running    0             33s   10.244.1.226   kind-worker   <none>           <none>\nimage-provider-7f5bc6bf-ggb7w      1/1     Running    0             33s   10.244.1.223   kind-worker   <none>           <none>\njaeger-55f499595b-5bsc8            1/1     Running    0             35s   10.244.1.206   kind-worker   <none>           <none>\nkafka-595d889c56-kzls6             1/1     Running    0             35s   10.244.1.207   kind-worker   <none>           <none>\nload-generator-68b6f899f5-56s67    1/1     Running    0             32s   10.244.1.229   kind-worker   <none>           <none>\nopensearch-0                       1/1     Running    0             35s   10.244.1.212   kind-worker   <none>           <none>\notel-collector-758b8784c-fqhgz     1/1     Running    0             32s   10.244.1.228   kind-worker   <none>           <none>\npayment-7597577cb5-t2bt5           1/1     Running    0             35s   10.244.1.213   kind-worker   <none>           <none>\nproduct-catalog-6988cd5f49-fpthq   1/1     Running    1 (13s ago)   34s   10.244.1.222   kind-worker   <none>           <none>\nprometheus-58b7bfb774-qqk7w        1/1     Running    0             33s   10.244.1.224   kind-worker   <none>           <none>\nquote-78bf8788-sjhsl               1/1     Running    0             33s   10.244.1.225   kind-worker   <none>           <none>\nrecommendation-7b49c8cb75-gscvw    1/1     Running    0             35s   10.244.1.210   kind-worker   <none>           <none>\nshipping-7f445d59dc-phg5h          1/1     Running    0             35s   10.244.1.208   kind-worker   <none>           <none>\nvalkey-cart-6475dcc67f-7hk8c       1/1     Running    0             35s   10.244.1.214   kind-worker   <none>           <none>\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl describe pod flagd-5f7bcb686-dxs4b -n astronomy-shop\")\n```"
        },
        {
            "role": "env",
            "content": "Name:             flagd-5f7bcb686-dxs4b\nNamespace:        astronomy-shop\nPriority:         0\nService Account:  astronomy-shop\nNode:             kind-worker/192.168.97.2\nStart Time:       Tue, 19 Aug 2025 20:49:27 +0000\nLabels:           app.kubernetes.io/component=flagd\n                  app.kubernetes.io/name=flagd\n                  opentelemetry.io/name=flagd\n                  pod-template-hash=5f7bcb686\nAnnotations:      kubectl.kubernetes.io/restartedAt: 2025-08-19T13:49:27-07:00\nStatus:           Running\nIP:               10.244.1.230\nIPs:\n  IP:           10.244.1.230\nControlled By:  ReplicaSet/flagd-5f7bcb686\nInit Containers:\n  init-config:\n    Container ID:  containerd://808134f093682d39b6e62c5bf0d1dab755f9a1be69117f4156b1b5720e9836b4\n    Image:         busybox\n    Image ID:      docker.io/library/busybox@sha256:ab33eacc8251e3807b85bb6dba570e4698c3998eca6f0fc2ccb60575a563ea74\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json\n    State:          Terminated\n      Reason:       Completed\n      Exit Code:    0\n      Started:      Tue, 19 Aug 2025 20:49:29 +0000\n      Finished:     Tue, 19 Aug 2025 20:49:29 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /config-ro from config-ro (rw)\n      /config-rw from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6bwrj (ro)\nContainers:\n  flagd:\n    Container ID:  containerd://6217648fed3fabc90efaebbc3707ee855d02fc8125b1b60026f71952d77a7260\n    Image:         ghcr.io/open-feature/flagd:v0.12.8\n    Image ID:      ghcr.io/open-feature/flagd@sha256:634bd05995f5fd0a1b8196822feb8c2d99d37be9e2a25cb17b5d6c4c8fd7e821\n    Ports:         8013/TCP, 8016/TCP\n    Host Ports:    0/TCP, 0/TCP\n    Command:\n      /flagd-build\n      start\n      --port\n      8013\n      --ofrep-port\n      8016\n      --uri\n      file:./etc/flagd/demo.flagd.json\n    State:          Running\n      Started:      Tue, 19 Aug 2025 20:49:30 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  75Mi\n    Requests:\n      memory:  75Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      FLAGD_METRICS_EXPORTER:                             otel\n      FLAGD_OTEL_COLLECTOR_URI:                           $(OTEL_COLLECTOR_NAME):4317\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /etc/flagd from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6bwrj (ro)\n  flagd-ui:\n    Container ID:   containerd://2ac33ce5f878ca0d56540dab7c17239cd7a8f210dd331d1b7cd49de720a47572\n    Image:          ghcr.io/open-telemetry/demo:2.0.2-flagd-ui\n    Image ID:       ghcr.io/open-telemetry/demo@sha256:655da6a8735b7bb7da2c36c8992387d03ae06420f2a06fbc499f2591889c1d03\n    Port:           4000/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Aug 2025 20:49:30 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  100Mi\n    Requests:\n      memory:  100Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      FLAGD_METRICS_EXPORTER:                             otel\n      OTEL_EXPORTER_OTLP_ENDPOINT:                        http://$(OTEL_COLLECTOR_NAME):4318\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /app/data from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6bwrj (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  config-rw:\n    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n    Medium:     \n    SizeLimit:  <unset>\n  config-ro:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      flagd-config\n    Optional:  false\n  kube-api-access-6bwrj:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  8s    default-scheduler  Successfully assigned astronomy-shop/flagd-5f7bcb686-dxs4b to kind-worker\n  Normal  Pulling    8s    kubelet            Pulling image \"busybox\"\n  Normal  Pulled     7s    kubelet            Successfully pulled image \"busybox\" in 898ms (898ms including waiting). Image size: 1913387 bytes.\n  Normal  Created    7s    kubelet            Created container: init-config\n  Normal  Started    6s    kubelet            Started container init-config\n  Normal  Pulled     5s    kubelet            Container image \"ghcr.io/open-feature/flagd:v0.12.8\" already present on machine\n  Normal  Created    5s    kubelet            Created container: flagd\n  Normal  Started    5s    kubelet            Started container flagd\n  Normal  Pulled     5s    kubelet            Container image \"ghcr.io/open-telemetry/demo:2.0.2-flagd-ui\" already present on machine\n  Normal  Created    5s    kubelet            Created container: flagd-ui\n  Normal  Started    5s    kubelet            Started container flagd-ui\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop product-catalog-6988cd5f49-fpthq -c product-catalog --previous; echo '===CURRENT==='; kubectl logs -n astronomy-shop product-catalog-6988cd5f49-fpthq -c product-catalog\")\n```"
        },
        {
            "role": "env",
            "content": "time=\"2025-08-19T20:48:54Z\" level=info msg=\"Loading Product Catalog...\"\ntime=\"2025-08-19T20:48:54Z\" level=info msg=\"Loaded 10 products\"\ntime=\"2025-08-19T20:48:54Z\" level=info msg=\"Product Catalog reload interval: 10\"\ntime=\"2025-08-19T20:48:54Z\" level=info msg=\"Product Catalog gRPC server started on port: 8080\"\ntime=\"2025-08-19T20:49:04Z\" level=info msg=\"Reloading Product Catalog...\"\n2025/08/19 20:49:11 traces export: context deadline exceeded: rpc error: code = DeadlineExceeded desc = context deadline exceeded while waiting for connections to become ready\n===CURRENT===\ntime=\"2025-08-19T20:49:15Z\" level=info msg=\"Loading Product Catalog...\"\ntime=\"2025-08-19T20:49:15Z\" level=info msg=\"Loaded 10 products\"\ntime=\"2025-08-19T20:49:15Z\" level=info msg=\"Product Catalog reload interval: 10\"\ntime=\"2025-08-19T20:49:15Z\" level=info msg=\"Product Catalog gRPC server started on port: 8080\"\ntime=\"2025-08-19T20:49:26Z\" level=info msg=\"Reloading Product Catalog...\"\n2025/08/19 20:49:35 traces export: context deadline exceeded: rpc error: code = DeadlineExceeded desc = context deadline exceeded while waiting for connections to become ready\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop otel-collector-758b8784c-fqhgz\")\n```"
        },
        {
            "role": "env",
            "content": "2025-08-19T20:48:55.964Z\tinfo\tservice@v0.131.0/service.go:214\tSetting up own telemetry...\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T20:48:55.966Z\tinfo\tmemorylimiter@v0.131.0/memorylimiter.go:149\tUsing percentage memory limiter\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.kind\": \"processor\", \"total_memory_mib\": 200, \"limit_percentage\": 80, \"spike_limit_percentage\": 25}\n2025-08-19T20:48:55.968Z\tinfo\tmemorylimiter@v0.131.0/memorylimiter.go:74\tMemory limiter configured\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.kind\": \"processor\", \"limit_mib\": 160, \"spike_limit_mib\": 50, \"check_interval\": 5}\n2025-08-19T20:48:55.968Z\tinfo\tspanmetricsconnector@v0.131.0/connector.go:114\tBuilding spanmetrics connector\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"spanmetrics\", \"otelcol.component.kind\": \"connector\", \"otelcol.signal\": \"traces\", \"otelcol.signal.output\": \"metrics\"}\n2025-08-19T20:48:55.971Z\tinfo\tottl@v0.131.0/parser_collection.go:646\tone or more paths were modified to include their context prefix, please rewrite them accordingly\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"transform\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"traces\", \"otelcol.signal\": \"traces\", \"values\": {\"[0]\": {\"original\": \"replace_pattern(name, \\\"\\\\\\\\?.*\\\", \\\"\\\")\", \"modified\": \"replace_pattern(span.name, \\\"\\\\\\\\?.*\\\", \\\"\\\")\"}, \"[1]\": {\"original\": \"replace_match(name, \\\"GET /api/products/*\\\", \\\"GET /api/products/{productId}\\\")\", \"modified\": \"replace_match(span.name, \\\"GET /api/products/*\\\", \\\"GET /api/products/{productId}\\\")\"}}}\n2025-08-19T20:48:55.973Z\tinfo\tbuilders/extension.go:50\tUnmaintained component. Actively looking for contributors. Component will become deprecated after 3 months of remaining unmaintained.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T20:48:55.975Z\tinfo\tservice@v0.131.0/service.go:276\tStarting otelcol-contrib...\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"Version\": \"0.131.0\", \"NumCPU\": 16}\n2025-08-19T20:48:55.975Z\tinfo\textensions/extensions.go:41\tStarting extensions...\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T20:48:55.975Z\tinfo\textensions/extensions.go:45\tExtension is starting...\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T20:48:55.976Z\tinfo\thealthcheckextension@v0.131.0/healthcheckextension.go:32\tStarting health_check extension\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\", \"config\": {\"Endpoint\":\"10.244.1.228:13133\",\"TLS\":{},\"CORS\":{},\"Auth\":{},\"MaxRequestBodySize\":0,\"IncludeMetadata\":false,\"ResponseHeaders\":null,\"CompressionAlgorithms\":null,\"ReadTimeout\":0,\"ReadHeaderTimeout\":0,\"WriteTimeout\":0,\"IdleTimeout\":0,\"Middlewares\":null,\"Path\":\"/\",\"ResponseBody\":null,\"CheckCollectorPipeline\":{\"Enabled\":false,\"Interval\":\"5m\",\"ExporterFailureThreshold\":5}}}\n2025-08-19T20:48:55.979Z\tinfo\textensions/extensions.go:62\tExtension started.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T20:48:55.989Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"metrics\", \"otelcol.signal\": \"metrics\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T20:48:55.989Z\tinfo\tspanmetricsconnector@v0.131.0/connector.go:207\tStarting spanmetrics connector\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"spanmetrics\", \"otelcol.component.kind\": \"connector\", \"otelcol.signal\": \"traces\", \"otelcol.signal.output\": \"metrics\"}\n2025-08-19T20:48:55.989Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"traces\", \"otelcol.signal\": \"traces\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T20:48:55.996Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:233\tStarting UDP server for Compact Thrift\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.228:6831\"}\n2025-08-19T20:48:56.005Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:337\tStarting HTTP server for Jaeger Thrift\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.228:14268\"}\n2025-08-19T20:48:56.011Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:362\tStarting gRPC server for Jaeger Protobuf\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.228:14250\"}\n2025-08-19T20:48:56.015Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T20:48:56.018Z\tinfo\totlpreceiver@v0.131.0/otlp.go:117\tStarting GRPC server\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlp\", \"otelcol.component.kind\": \"receiver\", \"endpoint\": \"10.244.1.228:4317\"}\n2025-08-19T20:48:56.019Z\tinfo\totlpreceiver@v0.131.0/otlp.go:175\tStarting HTTP server\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlp\", \"otelcol.component.kind\": \"receiver\", \"endpoint\": \"10.244.1.228:4318\"}\n2025-08-19T20:48:56.020Z\tinfo\thealthcheck/handler.go:131\tHealth Check state change\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\", \"status\": \"ready\"}\n2025-08-19T20:48:56.020Z\tinfo\tservice@v0.131.0/service.go:299\tEverything is ready. Begin running and processing data.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T20:48:57.188Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 2, \"metrics\": 31, \"data points\": 40}\n2025-08-19T20:48:57.192Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"4.113124165s\"}\n2025-08-19T20:48:57.391Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 3, \"data points\": 3}\n2025-08-19T20:48:57.394Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"3.566014515s\"}\n2025-08-19T20:48:57.593Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T20:48:57.809Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000847173, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:57.811Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 2}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:57.812Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 2}\n2025-08-19T20:48:57.812Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:48:58.013Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000683005, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:58.014Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 8}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:58.014Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 8}\n2025-08-19T20:48:58.014Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:48:58.597Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 9}\n2025-08-19T20:48:58.617Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000518837, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:58.617Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 1}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:58.617Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:48:58.617Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:48:58.798Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 20}\n2025-08-19T20:48:59.000Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 10, \"spans\": 28}\n2025-08-19T20:48:59.019Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000800339, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:59.020Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 19}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:59.020Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 6, \"log records\": 19}\n2025-08-19T20:48:59.020Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:48:59.201Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T20:48:59.402Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 16}\n2025-08-19T20:48:59.430Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000864797, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:59.430Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 1}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:48:59.430Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:48:59.430Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:48:59.604Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 21}\n2025-08-19T20:48:59.805Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 25}\n2025-08-19T20:49:00.037Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000925131, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:49:00.037Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 29}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:49:00.037Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 8, \"log records\": 29}\n2025-08-19T20:49:00.037Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:49:00.642Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000653963, \"reason\": \"dial tcp 10.96.65.109:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:49:00.643Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\", \"rejected_items\": 2}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T20:49:00.643Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 2}\n2025-08-19T20:49:00.643Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.65.109:9200: connect: connection refused\"}\n2025-08-19T20:49:00.808Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 15}\n2025-08-19T20:49:01.010Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 20}\n2025-08-19T20:49:01.309Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"8.094488137s\"}\n2025-08-19T20:49:03.008Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"8.350191925s\"}\n2025-08-19T20:49:04.610Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 7, \"log records\": 14}\n2025-08-19T20:49:05.748Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 37, \"log records\": 270}\n2025-08-19T20:49:05.992Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 25, \"log records\": 78}\n2025-08-19T20:49:06.000Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:07.003Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:07.041Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:49:07.100Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"6.591003158s\"}\n2025-08-19T20:49:07.666Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 17}\n2025-08-19T20:49:07.827Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 285}\n2025-08-19T20:49:07.867Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 40}\n2025-08-19T20:49:08.099Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 9, \"spans\": 49}\n2025-08-19T20:49:08.111Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 10, \"log records\": 45}\n2025-08-19T20:49:08.306Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 35}\n2025-08-19T20:49:08.335Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:08.507Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 12, \"spans\": 60}\n2025-08-19T20:49:08.709Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 17}\n2025-08-19T20:49:08.762Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 5}\n2025-08-19T20:49:08.772Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:08.911Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 16, \"spans\": 76}\n2025-08-19T20:49:09.055Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 16, \"log records\": 80}\n2025-08-19T20:49:09.112Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 9, \"spans\": 22}\n2025-08-19T20:49:09.315Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 45}\n2025-08-19T20:49:09.324Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:09.717Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 23}\n2025-08-19T20:49:09.739Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 16}\n2025-08-19T20:49:09.951Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 5, \"log records\": 6}\n2025-08-19T20:49:10.177Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 6}\n2025-08-19T20:49:10.433Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"6.975477126s\"}\n2025-08-19T20:49:10.601Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025/08/19 20:49:10 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:49:11.279Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:12.482Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"15.511353529s\"}\n2025-08-19T20:49:13.725Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"8.954671625s\"}\n2025-08-19T20:49:15.871Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:17.089Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:49:17.108Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"6.137543988s\"}\n2025-08-19T20:49:17.411Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"23.412248551s\"}\n2025-08-19T20:49:17.794Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 30}\n2025-08-19T20:49:17.996Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 21}\n2025-08-19T20:49:18.100Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 51}\n2025-08-19T20:49:18.199Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 139}\n2025-08-19T20:49:18.601Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 30}\n2025-08-19T20:49:18.712Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 2}\n2025-08-19T20:49:18.802Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 6}\n2025-08-19T20:49:19.005Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 21, \"spans\": 73}\n2025-08-19T20:49:19.156Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 10, \"log records\": 20}\n2025-08-19T20:49:19.209Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 18}\n2025-08-19T20:49:19.571Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 4, \"log records\": 4}\n2025-08-19T20:49:19.614Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 16, \"spans\": 82}\n2025-08-19T20:49:19.786Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T20:49:19.815Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 14, \"spans\": 74}\n2025-08-19T20:49:20.016Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 502}\n2025-08-19T20:49:20.080Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 15, \"log records\": 83}\n2025-08-19T20:49:20.294Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025/08/19 20:49:20 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:49:21.115Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 40}\n2025-08-19T20:49:21.760Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 3}\n2025-08-19T20:49:22.057Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 13, \"log records\": 64}\n2025-08-19T20:49:22.361Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:22.728Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"9.439110746s\"}\n2025-08-19T20:49:24.332Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.198.18:9090: connect: connection refused\", \"interval\": \"7.493230344s\"}\n2025-08-19T20:49:27.150Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:49:27.940Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 42}\n2025-08-19T20:49:28.164Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 35}\n2025-08-19T20:49:28.214Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 14, \"log records\": 78}\n2025-08-19T20:49:28.398Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 9, \"spans\": 42}\n2025-08-19T20:49:28.564Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 5, \"log records\": 5}\n2025-08-19T20:49:28.609Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 43}\n2025-08-19T20:49:28.794Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:28.843Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 16}\n2025-08-19T20:49:29.038Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 13, \"log records\": 50}\n2025-08-19T20:49:29.068Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 19, \"spans\": 78}\n2025-08-19T20:49:29.271Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:29.274Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 39}\n2025-08-19T20:49:29.676Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T20:49:29.894Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 48}\n2025-08-19T20:49:29.948Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:30.165Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 49}\n2025-08-19T20:49:30.302Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 21}\n2025-08-19T20:49:30.875Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025/08/19 20:49:30 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:49:31.106Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 8, \"log records\": 25}\n2025-08-19T20:49:31.326Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:32.493Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.226.66:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T20:49:37.080Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:49:38.138Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 32}\n2025-08-19T20:49:38.238Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 57}\n2025-08-19T20:49:38.347Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 30}\n2025-08-19T20:49:38.552Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 38}\n2025-08-19T20:49:38.690Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:38.757Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 18, \"spans\": 86}\n2025-08-19T20:49:38.924Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T20:49:38.980Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 21, \"spans\": 60}\n2025-08-19T20:49:39.187Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 19}\n2025-08-19T20:49:39.256Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 14, \"log records\": 78}\n2025-08-19T20:49:39.595Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 46}\n2025-08-19T20:49:39.810Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 37}\n2025-08-19T20:49:39.900Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T20:49:40.021Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 20}\n2025-08-19T20:49:40.138Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 10, \"log records\": 28}\n2025-08-19T20:49:40.426Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 19}\n2025-08-19T20:49:40.781Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025/08/19 20:49:40 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T20:49:41.010Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 46}\n2025-08-19T20:49:41.991Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 27}\n2025-08-19T20:49:42.244Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 27}\n2025-08-19T20:49:47.170Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T20:49:48.197Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 34}\n2025-08-19T20:49:48.402Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 16}\n2025-08-19T20:49:48.530Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"2218bff1-5475-4a48-a33b-403447f4e0c4\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl describe pod product-catalog-6988cd5f49-fpthq -n astronomy-shop\")\n```"
        },
        {
            "role": "env",
            "content": "Name:             product-catalog-6988cd5f49-fpthq\nNamespace:        astronomy-shop\nPriority:         0\nService Account:  astronomy-shop\nNode:             kind-worker/192.168.97.2\nStart Time:       Tue, 19 Aug 2025 20:48:53 +0000\nLabels:           app.kubernetes.io/component=product-catalog\n                  app.kubernetes.io/name=product-catalog\n                  opentelemetry.io/name=product-catalog\n                  pod-template-hash=6988cd5f49\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.222\nIPs:\n  IP:           10.244.1.222\nControlled By:  ReplicaSet/product-catalog-6988cd5f49\nContainers:\n  product-catalog:\n    Container ID:   containerd://2e5498d72fa03b40dfb4acf81f8140b305eca4a552f1ad288d77faa4b6347a37\n    Image:          ghcr.io/open-telemetry/demo:2.0.2-product-catalog\n    Image ID:       ghcr.io/open-telemetry/demo@sha256:050a0fc2026b75cc8716cbd5daf9c9e5fd552808a59928a6bfca18bfb8edd2d5\n    Port:           8080/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Aug 2025 20:49:15 +0000\n    Last State:     Terminated\n      Reason:       OOMKilled\n      Exit Code:    137\n      Started:      Tue, 19 Aug 2025 20:48:54 +0000\n      Finished:     Tue, 19 Aug 2025 20:49:14 +0000\n    Ready:          True\n    Restart Count:  1\n    Limits:\n      memory:  20Mi\n    Requests:\n      memory:  20Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      PRODUCT_CATALOG_PORT:                               8080\n      PRODUCT_CATALOG_RELOAD_INTERVAL:                    10\n      FLAGD_HOST:                                         flagd\n      FLAGD_PORT:                                         8013\n      OTEL_EXPORTER_OTLP_ENDPOINT:                        http://$(OTEL_COLLECTOR_NAME):4317\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /usr/src/app/products from product-catalog-products (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bbstm (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  product-catalog-products:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      product-catalog-products\n    Optional:  false\n  kube-api-access-bbstm:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age                From               Message\n  ----    ------     ----               ----               -------\n  Normal  Scheduled  66s                default-scheduler  Successfully assigned astronomy-shop/product-catalog-6988cd5f49-fpthq to kind-worker\n  Normal  Pulled     45s (x2 over 66s)  kubelet            Container image \"ghcr.io/open-telemetry/demo:2.0.2-product-catalog\" already present on machine\n  Normal  Created    45s (x2 over 66s)  kubelet            Created container: product-catalog\n  Normal  Started    45s (x2 over 66s)  kubelet            Started container product-catalog\n"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "env",
            "content": "Error parsing response: No API call found!"
        },
        {
            "role": "assistant",
            "content": "```\nsubmit([\"product-catalog\"])\n```"
        },
        {
            "role": "env",
            "content": "1"
        }
    ],
    "results": {
        "Localization Accuracy": 100.0,
        "TTL": 80.49937772750854,
        "steps": 7,
        "in_tokens": 36785,
        "out_tokens": 171,
        "success": true,
        "is_subset": true
    }
}