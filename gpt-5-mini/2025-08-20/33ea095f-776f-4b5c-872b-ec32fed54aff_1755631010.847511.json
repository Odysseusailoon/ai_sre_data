{
    "agent": "gpt-w-shell",
    "session_id": "33ea095f-776f-4b5c-872b-ec32fed54aff",
    "problem_id": "astronomy_shop_image_slow_load-detection-1",
    "start_time": 1755631010.847511,
    "end_time": 1755631047.1202948,
    "trace": [
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl get pods -n astronomy-shop -o wide\")\n```"
        },
        {
            "role": "env",
            "content": "NAME                               READY   STATUS     RESTARTS   AGE   IP            NODE          NOMINATED NODE   READINESS GATES\naccounting-567f87bbcd-4xwnj        1/1     Running    0          34s   10.244.1.58   kind-worker   <none>           <none>\nad-856c77f595-rz99q                1/1     Running    0          34s   10.244.1.61   kind-worker   <none>           <none>\ncart-6fd857c656-h76zw              1/1     Running    0          34s   10.244.1.60   kind-worker   <none>           <none>\ncheckout-5bc54f8cd8-zcxs5          1/1     Running    0          34s   10.244.1.62   kind-worker   <none>           <none>\ncurrency-5864f94d89-x94jq          1/1     Running    0          34s   10.244.1.63   kind-worker   <none>           <none>\nemail-59d9ffc758-zllj8             1/1     Running    0          32s   10.244.1.72   kind-worker   <none>           <none>\nflagd-64968487c9-q9rnr             0/2     Init:0/1   0          1s    <none>        kind-worker   <none>           <none>\nflagd-86575d5796-4lh78             2/2     Running    0          33s   10.244.1.67   kind-worker   <none>           <none>\nfraud-detection-65868bcdb5-66hdc   1/1     Running    0          34s   10.244.1.52   kind-worker   <none>           <none>\nfrontend-7d6b77c58-s5szp           1/1     Running    0          31s   10.244.1.74   kind-worker   <none>           <none>\nfrontend-proxy-548b4649d7-hrp9l    1/1     Running    0          33s   10.244.1.65   kind-worker   <none>           <none>\ngrafana-6b9fb84fb7-frvf6           1/1     Running    0          32s   10.244.1.70   kind-worker   <none>           <none>\nimage-provider-7f5bc6bf-pbq9r      1/1     Running    0          34s   10.244.1.54   kind-worker   <none>           <none>\njaeger-55f499595b-zftfq            1/1     Running    0          31s   10.244.1.73   kind-worker   <none>           <none>\nkafka-595d889c56-n9tmq             1/1     Running    0          34s   10.244.1.55   kind-worker   <none>           <none>\nload-generator-68b6f899f5-jsctz    1/1     Running    0          32s   10.244.1.68   kind-worker   <none>           <none>\nopensearch-0                       1/1     Running    0          34s   10.244.1.57   kind-worker   <none>           <none>\notel-collector-758b8784c-rfj5r     1/1     Running    0          32s   10.244.1.69   kind-worker   <none>           <none>\npayment-7597577cb5-9k87l           1/1     Running    0          32s   10.244.1.71   kind-worker   <none>           <none>\nproduct-catalog-6988cd5f49-gmhxn   1/1     Running    0          34s   10.244.1.53   kind-worker   <none>           <none>\nprometheus-58b7bfb774-6nngz        1/1     Running    0          34s   10.244.1.56   kind-worker   <none>           <none>\nquote-78bf8788-bz47v               1/1     Running    0          34s   10.244.1.51   kind-worker   <none>           <none>\nrecommendation-7b49c8cb75-hchzt    1/1     Running    0          33s   10.244.1.64   kind-worker   <none>           <none>\nshipping-7f445d59dc-b7x57          1/1     Running    0          33s   10.244.1.66   kind-worker   <none>           <none>\nvalkey-cart-6475dcc67f-zndnq       1/1     Running    0          34s   10.244.1.59   kind-worker   <none>           <none>\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl describe pod flagd-64968487c9-q9rnr -n astronomy-shop\")\n```"
        },
        {
            "role": "env",
            "content": "Name:             flagd-64968487c9-q9rnr\nNamespace:        astronomy-shop\nPriority:         0\nService Account:  astronomy-shop\nNode:             kind-worker/192.168.97.2\nStart Time:       Tue, 19 Aug 2025 19:16:50 +0000\nLabels:           app.kubernetes.io/component=flagd\n                  app.kubernetes.io/name=flagd\n                  opentelemetry.io/name=flagd\n                  pod-template-hash=64968487c9\nAnnotations:      kubectl.kubernetes.io/restartedAt: 2025-08-19T12:16:50-07:00\nStatus:           Running\nIP:               10.244.1.75\nIPs:\n  IP:           10.244.1.75\nControlled By:  ReplicaSet/flagd-64968487c9\nInit Containers:\n  init-config:\n    Container ID:  containerd://fea6acb1daee6877afcf1266a31436def57c23e29aa6ea144211b527ef6b4b2e\n    Image:         busybox\n    Image ID:      docker.io/library/busybox@sha256:ab33eacc8251e3807b85bb6dba570e4698c3998eca6f0fc2ccb60575a563ea74\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json\n    State:          Terminated\n      Reason:       Completed\n      Exit Code:    0\n      Started:      Tue, 19 Aug 2025 19:16:52 +0000\n      Finished:     Tue, 19 Aug 2025 19:16:52 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /config-ro from config-ro (rw)\n      /config-rw from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xzfq8 (ro)\nContainers:\n  flagd:\n    Container ID:  containerd://ad3833e60a09ca4bcb6ed1a43f3589aa1dc0167bd361b2994a9709aa5bc32af0\n    Image:         ghcr.io/open-feature/flagd:v0.12.8\n    Image ID:      ghcr.io/open-feature/flagd@sha256:634bd05995f5fd0a1b8196822feb8c2d99d37be9e2a25cb17b5d6c4c8fd7e821\n    Ports:         8013/TCP, 8016/TCP\n    Host Ports:    0/TCP, 0/TCP\n    Command:\n      /flagd-build\n      start\n      --port\n      8013\n      --ofrep-port\n      8016\n      --uri\n      file:./etc/flagd/demo.flagd.json\n    State:          Running\n      Started:      Tue, 19 Aug 2025 19:16:53 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  75Mi\n    Requests:\n      memory:  75Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      FLAGD_METRICS_EXPORTER:                             otel\n      FLAGD_OTEL_COLLECTOR_URI:                           $(OTEL_COLLECTOR_NAME):4317\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /etc/flagd from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xzfq8 (ro)\n  flagd-ui:\n    Container ID:   containerd://07677f23e4b475093df8f781c5d01d6bec974149df5043c0af9f5df64bd1cb44\n    Image:          ghcr.io/open-telemetry/demo:2.0.2-flagd-ui\n    Image ID:       ghcr.io/open-telemetry/demo@sha256:655da6a8735b7bb7da2c36c8992387d03ae06420f2a06fbc499f2591889c1d03\n    Port:           4000/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Aug 2025 19:16:54 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  100Mi\n    Requests:\n      memory:  100Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      FLAGD_METRICS_EXPORTER:                             otel\n      OTEL_EXPORTER_OTLP_ENDPOINT:                        http://$(OTEL_COLLECTOR_NAME):4318\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /app/data from config-rw (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xzfq8 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  config-rw:\n    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n    Medium:     \n    SizeLimit:  <unset>\n  config-ro:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      flagd-config\n    Optional:  false\n  kube-api-access-xzfq8:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  6s    default-scheduler  Successfully assigned astronomy-shop/flagd-64968487c9-q9rnr to kind-worker\n  Normal  Pulling    5s    kubelet            Pulling image \"busybox\"\n  Normal  Pulled     4s    kubelet            Successfully pulled image \"busybox\" in 795ms (795ms including waiting). Image size: 1913387 bytes.\n  Normal  Created    4s    kubelet            Created container: init-config\n  Normal  Started    4s    kubelet            Started container init-config\n  Normal  Pulled     3s    kubelet            Container image \"ghcr.io/open-feature/flagd:v0.12.8\" already present on machine\n  Normal  Created    3s    kubelet            Created container: flagd\n  Normal  Started    3s    kubelet            Started container flagd\n  Normal  Pulled     3s    kubelet            Container image \"ghcr.io/open-telemetry/demo:2.0.2-flagd-ui\" already present on machine\n  Normal  Created    3s    kubelet            Created container: flagd-ui\n  Normal  Started    2s    kubelet            Started container flagd-ui\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl describe pod payment-7597577cb5-9k87l -n astronomy-shop\")\n```"
        },
        {
            "role": "env",
            "content": "Name:             payment-7597577cb5-9k87l\nNamespace:        astronomy-shop\nPriority:         0\nService Account:  astronomy-shop\nNode:             kind-worker/192.168.97.2\nStart Time:       Tue, 19 Aug 2025 19:16:19 +0000\nLabels:           app.kubernetes.io/component=payment\n                  app.kubernetes.io/name=payment\n                  opentelemetry.io/name=payment\n                  pod-template-hash=7597577cb5\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.71\nIPs:\n  IP:           10.244.1.71\nControlled By:  ReplicaSet/payment-7597577cb5\nContainers:\n  payment:\n    Container ID:   containerd://0687e550364a9ccb278a5aaa1b641ed2e8594cb824e0ca4878dd2c327d23c667\n    Image:          ghcr.io/open-telemetry/demo:2.0.2-payment\n    Image ID:       ghcr.io/open-telemetry/demo@sha256:33f327b357617379bfa3b292f430d1f06e66e2872494125a40bae14d8fe57d87\n    Port:           8080/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Aug 2025 19:16:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      memory:  120Mi\n    Requests:\n      memory:  120Mi\n    Environment:\n      OTEL_SERVICE_NAME:                                   (v1:metadata.labels['app.kubernetes.io/component'])\n      OTEL_COLLECTOR_NAME:                                otel-collector\n      OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE:  cumulative\n      PAYMENT_PORT:                                       8080\n      FLAGD_HOST:                                         flagd\n      FLAGD_PORT:                                         8013\n      OTEL_EXPORTER_OTLP_ENDPOINT:                        http://$(OTEL_COLLECTOR_NAME):4317\n      OTEL_RESOURCE_ATTRIBUTES:                           service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f7krc (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-f7krc:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  44s   default-scheduler  Successfully assigned astronomy-shop/payment-7597577cb5-9k87l to kind-worker\n  Normal  Pulled     43s   kubelet            Container image \"ghcr.io/open-telemetry/demo:2.0.2-payment\" already present on machine\n  Normal  Created    43s   kubelet            Created container: payment\n  Normal  Started    43s   kubelet            Started container payment\n"
        },
        {
            "role": "assistant",
            "content": "```\nexec_shell(\"kubectl logs -n astronomy-shop otel-collector-758b8784c-rfj5r\")\n```"
        },
        {
            "role": "env",
            "content": "2025-08-19T19:16:20.388Z\tinfo\tservice@v0.131.0/service.go:214\tSetting up own telemetry...\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T19:16:20.392Z\tinfo\tmemorylimiter@v0.131.0/memorylimiter.go:149\tUsing percentage memory limiter\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.kind\": \"processor\", \"total_memory_mib\": 200, \"limit_percentage\": 80, \"spike_limit_percentage\": 25}\n2025-08-19T19:16:20.393Z\tinfo\tmemorylimiter@v0.131.0/memorylimiter.go:74\tMemory limiter configured\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.kind\": \"processor\", \"limit_mib\": 160, \"spike_limit_mib\": 50, \"check_interval\": 5}\n2025-08-19T19:16:20.393Z\tinfo\tspanmetricsconnector@v0.131.0/connector.go:114\tBuilding spanmetrics connector\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"spanmetrics\", \"otelcol.component.kind\": \"connector\", \"otelcol.signal\": \"traces\", \"otelcol.signal.output\": \"metrics\"}\n2025-08-19T19:16:20.394Z\tinfo\tottl@v0.131.0/parser_collection.go:646\tone or more paths were modified to include their context prefix, please rewrite them accordingly\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"transform\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"traces\", \"otelcol.signal\": \"traces\", \"values\": {\"[0]\": {\"original\": \"replace_pattern(name, \\\"\\\\\\\\?.*\\\", \\\"\\\")\", \"modified\": \"replace_pattern(span.name, \\\"\\\\\\\\?.*\\\", \\\"\\\")\"}, \"[1]\": {\"original\": \"replace_match(name, \\\"GET /api/products/*\\\", \\\"GET /api/products/{productId}\\\")\", \"modified\": \"replace_match(span.name, \\\"GET /api/products/*\\\", \\\"GET /api/products/{productId}\\\")\"}}}\n2025-08-19T19:16:20.397Z\tinfo\tbuilders/extension.go:50\tUnmaintained component. Actively looking for contributors. Component will become deprecated after 3 months of remaining unmaintained.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T19:16:20.399Z\tinfo\tservice@v0.131.0/service.go:276\tStarting otelcol-contrib...\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"Version\": \"0.131.0\", \"NumCPU\": 16}\n2025-08-19T19:16:20.399Z\tinfo\textensions/extensions.go:41\tStarting extensions...\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T19:16:20.399Z\tinfo\textensions/extensions.go:45\tExtension is starting...\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T19:16:20.399Z\tinfo\thealthcheckextension@v0.131.0/healthcheckextension.go:32\tStarting health_check extension\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\", \"config\": {\"Endpoint\":\"10.244.1.69:13133\",\"TLS\":{},\"CORS\":{},\"Auth\":{},\"MaxRequestBodySize\":0,\"IncludeMetadata\":false,\"ResponseHeaders\":null,\"CompressionAlgorithms\":null,\"ReadTimeout\":0,\"ReadHeaderTimeout\":0,\"WriteTimeout\":0,\"IdleTimeout\":0,\"Middlewares\":null,\"Path\":\"/\",\"ResponseBody\":null,\"CheckCollectorPipeline\":{\"Enabled\":false,\"Interval\":\"5m\",\"ExporterFailureThreshold\":5}}}\n2025-08-19T19:16:20.403Z\tinfo\textensions/extensions.go:62\tExtension started.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\"}\n2025-08-19T19:16:20.411Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"metrics\", \"otelcol.signal\": \"metrics\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T19:16:20.411Z\tinfo\tspanmetricsconnector@v0.131.0/connector.go:207\tStarting spanmetrics connector\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"spanmetrics\", \"otelcol.component.kind\": \"connector\", \"otelcol.signal\": \"traces\", \"otelcol.signal.output\": \"metrics\"}\n2025-08-19T19:16:20.424Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T19:16:20.430Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #2 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: \"jaeger-collector:4317\", ServerName: \"jaeger-collector:4317\", }. Err: connection error: desc = \"transport: Error while dialing: dial tcp: lookup jaeger-collector on 10.96.0.10:53: no such host\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:20.431Z\tinfo\totlpreceiver@v0.131.0/otlp.go:117\tStarting GRPC server\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlp\", \"otelcol.component.kind\": \"receiver\", \"endpoint\": \"10.244.1.69:4317\"}\n2025-08-19T19:16:20.431Z\tinfo\totlpreceiver@v0.131.0/otlp.go:175\tStarting HTTP server\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlp\", \"otelcol.component.kind\": \"receiver\", \"endpoint\": \"10.244.1.69:4318\"}\n2025-08-19T19:16:20.432Z\tinfo\tkube/client.go:172\tk8s filtering\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"k8sattributes\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"traces\", \"otelcol.signal\": \"traces\", \"labelSelector\": \"\", \"fieldSelector\": \"\"}\n2025-08-19T19:16:20.460Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:233\tStarting UDP server for Compact Thrift\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.69:6831\"}\n2025-08-19T19:16:20.468Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:337\tStarting HTTP server for Jaeger Thrift\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.69:14268\"}\n2025-08-19T19:16:20.469Z\tinfo\tjaegerreceiver@v0.131.0/trace_receiver.go:362\tStarting gRPC server for Jaeger Protobuf\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"jaeger\", \"otelcol.component.kind\": \"receiver\", \"otelcol.signal\": \"traces\", \"endpoint\": \"10.244.1.69:14250\"}\n2025-08-19T19:16:20.474Z\tinfo\thealthcheck/handler.go:131\tHealth Check state change\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"health_check\", \"otelcol.component.kind\": \"extension\", \"status\": \"ready\"}\n2025-08-19T19:16:20.474Z\tinfo\tservice@v0.131.0/service.go:299\tEverything is ready. Begin running and processing data.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}}\n2025-08-19T19:16:21.439Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #2 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: \"jaeger-collector:4317\", ServerName: \"jaeger-collector:4317\", }. Err: connection error: desc = \"transport: Error while dialing: dial tcp: lookup jaeger-collector on 10.96.0.10:53: no such host\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:21.647Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 2, \"metrics\": 28, \"data points\": 37}\n2025-08-19T19:16:21.654Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"3.080232255s\"}\n2025-08-19T19:16:22.862Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 3, \"data points\": 4}\n2025-08-19T19:16:22.866Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"5.095136742s\"}\n2025-08-19T19:16:22.890Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.001422755, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:22.893Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 3}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:22.893Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 3}\n2025-08-19T19:16:22.893Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:23.066Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T19:16:23.269Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T19:16:23.470Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T19:16:23.497Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000748878, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:23.497Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 17}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:23.497Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 17}\n2025-08-19T19:16:23.497Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:23.672Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 38}\n2025-08-19T19:16:23.699Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000667294, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:23.701Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 1}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:23.701Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:23.701Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:23.872Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 20}\n2025-08-19T19:16:23.912Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000793295, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:23.912Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 19}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:23.912Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 4, \"log records\": 19}\n2025-08-19T19:16:23.912Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:24.514Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000612377, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:24.517Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 1}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:24.517Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:24.517Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:24.740Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"9.911238143s\"}\n2025-08-19T19:16:24.921Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 0.000687253, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:24.922Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 2}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:24.922Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T19:16:24.922Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:25.077Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 35}\n2025-08-19T19:16:25.280Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 9, \"spans\": 37}\n2025-08-19T19:16:25.683Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 29}\n2025-08-19T19:16:25.884Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 19}\n2025-08-19T19:16:26.161Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 1.037333757, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:26.161Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 1}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:26.161Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:26.161Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:26.286Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T19:16:27.378Z\terror\topensearchexporter@v0.131.0/logger.go:36\tRequest failed.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"path\": \"/_bulk\", \"method\": \"POST\", \"duration\": 1.015126467, \"reason\": \"dial tcp 10.96.205.57:9200: connect: connection refused\"}\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*clientLogger).LogRoundTrip\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/logger.go:36\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).logRoundTrip\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:498\ngithub.com/opensearch-project/opensearch-go/v2/opensearchtransport.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchtransport/opensearchtransport.go:337\ngithub.com/opensearch-project/opensearch-go/v2.(*Client).Perform\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearch.go:267\ngithub.com/opensearch-project/opensearch-go/v2/opensearchapi.BulkRequest.Do\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchapi/api.bulk.go:192\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*worker).flush\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:552\ngithub.com/opensearch-project/opensearch-go/v2/opensearchutil.(*bulkIndexer).Close\n\tgithub.com/opensearch-project/opensearch-go/v2@v2.3.0/opensearchutil/bulk_indexer.go:299\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logBulkIndexer).close\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/log_bulk_indexer.go:41\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter.(*logExporter).pushLogData\n\tgithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter@v0.131.0/sso_log_exporter.go:88\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogs.requestConsumeFromLogs.func2\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:136\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal/sender.(*sender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/sender/sender.go:31\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*retrySender).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/retry_sender.go:91\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*obsReportSender[...]).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/obs_report_sender.go:92\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:115\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:27.378Z\terror\tinternal/base_exporter.go:117\tExporting failed. Rejecting data. Try enabling sending_queue to survive temporary failures.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"opensearch\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\", \"rejected_items\": 56}\ngo.opentelemetry.io/collector/exporter/exporterhelper/internal.(*BaseExporter).Send\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/internal/base_exporter.go:117\ngo.opentelemetry.io/collector/exporter/exporterhelper.NewLogsRequest.newConsumeLogs.func1\n\tgo.opentelemetry.io/collector/exporter@v0.131.0/exporterhelper/logs.go:191\ngo.opentelemetry.io/collector/consumer.ConsumeLogsFunc.ConsumeLogs\n\tgo.opentelemetry.io/collector/consumer@v1.37.0/logs.go:27\ngo.opentelemetry.io/collector/internal/fanoutconsumer.(*logsConsumer).ConsumeLogs\n\tgo.opentelemetry.io/collector/internal/fanoutconsumer@v0.131.0/logs.go:64\ngo.opentelemetry.io/collector/processor/batchprocessor.(*batchLogs).export\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:543\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).sendItems\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:262\ngo.opentelemetry.io/collector/processor/batchprocessor.(*shard[...]).startLoop\n\tgo.opentelemetry.io/collector/processor/batchprocessor@v0.131.0/batch_processor.go:222\n2025-08-19T19:16:27.378Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 15, \"log records\": 56}\n2025-08-19T19:16:27.378Z\twarn\tbatchprocessor@v0.131.0/batch_processor.go:264\tSender failed\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"batch\", \"otelcol.component.kind\": \"processor\", \"otelcol.pipeline.id\": \"logs\", \"otelcol.signal\": \"logs\", \"error\": \"not retryable error: Permanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\\nPermanent error: Permanent error: flush: dial tcp 10.96.205.57:9200: connect: connection refused\"}\n2025-08-19T19:16:27.962Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"9.841827868s\"}\n2025-08-19T19:16:30.144Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 10, \"log records\": 141}\n2025-08-19T19:16:30.423Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:30.483Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 37, \"log records\": 140}\n2025-08-19T19:16:31.427Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:31.532Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T19:16:32.568Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"3.210998062s\"}\n2025-08-19T19:16:32.849Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:33.015Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 6, \"log records\": 24}\n2025-08-19T19:16:33.162Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 31}\n2025-08-19T19:16:33.362Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T19:16:33.567Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 6}\n2025-08-19T19:16:33.701Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:33.767Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 11, \"spans\": 33}\n2025-08-19T19:16:33.925Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 6, \"log records\": 26}\n2025-08-19T19:16:33.969Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 11}\n2025-08-19T19:16:34.172Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T19:16:34.344Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 5}\n2025-08-19T19:16:34.373Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 37}\n2025-08-19T19:16:34.573Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T19:16:34.576Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 2}\n2025-08-19T19:16:34.658Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"11.310333695s\"}\n2025-08-19T19:16:34.777Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 16}\n2025-08-19T19:16:34.805Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 13, \"log records\": 51}\n2025-08-19T19:16:34.977Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 29}\n2025-08-19T19:16:35.315Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 3}\n2025-08-19T19:16:35.342Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025/08/19 19:16:35 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T19:16:35.620Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 12}\n2025-08-19T19:16:35.786Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"6.518358585s\"}\n2025-08-19T19:16:35.851Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 8, \"log records\": 29}\n2025-08-19T19:16:36.469Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 4}\n2025-08-19T19:16:37.806Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"16.483032771s\"}\n2025-08-19T19:16:39.971Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:41.594Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T19:16:41.596Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"7.430903529s\"}\n2025-08-19T19:16:42.307Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"12.067763558s\"}\n2025-08-19T19:16:43.248Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 34}\n2025-08-19T19:16:43.455Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 28}\n2025-08-19T19:16:43.656Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T19:16:43.857Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 14, \"spans\": 36}\n2025-08-19T19:16:43.888Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 9, \"log records\": 13}\n2025-08-19T19:16:44.059Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 15}\n2025-08-19T19:16:44.270Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T19:16:44.471Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 11, \"spans\": 47}\n2025-08-19T19:16:44.513Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 3, \"log records\": 4}\n2025-08-19T19:16:44.873Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 20}\n2025-08-19T19:16:44.929Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 7, \"log records\": 44}\n2025-08-19T19:16:45.074Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 49}\n2025-08-19T19:16:45.275Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 11}\n2025-08-19T19:16:45.342Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025/08/19 19:16:45 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T19:16:45.978Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 32}\n2025-08-19T19:16:45.990Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"11.432479423s\"}\n2025-08-19T19:16:46.396Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:46.635Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:46.853Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:16:46.942Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 73}\n2025-08-19T19:16:47.355Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:47.764Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:49.061Z\tinfo\tinternal/retry_sender.go:133\tExporting failed. Will retry the request after interval.\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"otlphttp/prometheus\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"error\": \"failed to make an HTTP request: Post \\\"http://prometheus:9090/api/v1/otlp/v1/metrics\\\": dial tcp 10.96.74.26:9090: connect: connection refused\", \"interval\": \"7.133476488s\"}\n2025-08-19T19:16:51.723Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T19:16:53.295Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 10}\n2025-08-19T19:16:53.906Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 18, \"spans\": 69}\n2025-08-19T19:16:54.047Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 6, \"log records\": 8}\n2025-08-19T19:16:54.141Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 21}\n2025-08-19T19:16:54.398Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:16:54.569Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 5}\n2025-08-19T19:16:54.694Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 5}\n2025-08-19T19:16:54.800Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 9, \"spans\": 59}\n2025/08/19 19:16:55 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T19:16:55.456Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 26}\n2025-08-19T19:16:55.500Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 51}\n2025-08-19T19:16:55.674Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 3, \"spans\": 7}\n2025-08-19T19:16:55.959Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 63}\n2025-08-19T19:16:56.058Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T19:16:56.196Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 6, \"spans\": 26}\n2025-08-19T19:16:56.328Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 38}\n2025-08-19T19:16:56.612Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 20}\n2025-08-19T19:16:57.113Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 7, \"log records\": 27}\n2025-08-19T19:16:57.578Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 3}\n2025-08-19T19:16:57.850Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 3}\n2025-08-19T19:16:58.424Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 34}\n2025-08-19T19:16:58.650Z\twarn\tgrpc@v1.74.2/clientconn.go:1414\t[core] [Channel #1 SubChannel #37]grpc: addrConn.createTransport failed to connect to {Addr: \"10.96.72.58:4318\", ServerName: \"otel-collector:4318\", }. Err: connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"grpc_log\": true}\n2025-08-19T19:17:01.706Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T19:17:03.423Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 6}\n2025-08-19T19:17:03.634Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 35}\n2025-08-19T19:17:03.850Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 19, \"spans\": 84}\n2025-08-19T19:17:04.080Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 55}\n2025-08-19T19:17:04.223Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 12, \"log records\": 62}\n2025-08-19T19:17:04.307Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 21}\n2025-08-19T19:17:04.523Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 2}\n2025-08-19T19:17:04.950Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 20}\n2025-08-19T19:17:05.126Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 9, \"log records\": 12}\n2025-08-19T19:17:05.234Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 15, \"spans\": 71}\n2025-08-19T19:17:05.395Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025/08/19 19:17:05 failed to upload metrics: reader collect and export timeout: rpc error: code = Unavailable desc = connection error: desc = \"error reading server preface: http2: failed reading the frame payload: http2: frame too large, note that the frame header looked like an HTTP/1.1 header\"\n2025-08-19T19:17:05.488Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 12, \"spans\": 52}\n2025-08-19T19:17:05.720Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 7, \"spans\": 44}\n2025-08-19T19:17:05.841Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:17:05.969Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 28}\n2025-08-19T19:17:06.146Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 14, \"log records\": 89}\n2025-08-19T19:17:07.058Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 10, \"log records\": 28}\n2025-08-19T19:17:07.430Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:17:07.916Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 2}\n2025-08-19T19:17:08.223Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 11, \"log records\": 63}\n2025-08-19T19:17:11.618Z\tinfo\tMetrics\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\", \"resource metrics\": 1, \"metrics\": 29, \"data points\": 34}\n2025-08-19T19:17:13.617Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 1, \"spans\": 23}\n2025-08-19T19:17:13.824Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 16, \"spans\": 48}\n2025-08-19T19:17:14.037Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 50}\n2025-08-19T19:17:14.248Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 2, \"spans\": 10}\n2025-08-19T19:17:14.457Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 21}\n2025-08-19T19:17:14.572Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 2, \"log records\": 6}\n2025-08-19T19:17:14.668Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 5, \"spans\": 25}\n2025-08-19T19:17:14.834Z\tinfo\tLogs\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"logs\", \"resource logs\": 1, \"log records\": 1}\n2025-08-19T19:17:14.879Z\tinfo\tTraces\t{\"resource\": {\"service.instance.id\": \"4f091c28-f51f-4b8f-b1f7-0f35b77cfdf6\", \"service.name\": \"otelcol-contrib\", \"service.version\": \"0.131.0\"}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\", \"resource spans\": 4, \"spans\": 16}\n"
        },
        {
            "role": "assistant",
            "content": "```\nsubmit(\"Yes\")\n```"
        },
        {
            "role": "env",
            "content": "1"
        }
    ],
    "results": {
        "Detection Accuracy": "Correct",
        "TTD": 36.2727837562561,
        "steps": 5,
        "in_tokens": 39702,
        "out_tokens": 104
    }
}